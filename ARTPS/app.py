"""
ARTPS - Otonom Bilimsel KeÅŸif Sistemi
Streamlit Web ArayÃ¼zÃ¼ (Hibrit Model - Derinlik + Dinamik DeÄŸer)
"""

import streamlit as st
import torch
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D  # 3D plotting iÃ§in gerekli
from PIL import Image
import os
from pathlib import Path
from src.models.optimized_autoencoder import OptimizedAutoencoder
from src.models.depth_enhanced_classifier import DepthEnhancedClassifier
from src.models.anomaly import PaDiM, PaDiMConfig, PatchCore, PatchCoreConfig

# Transformers'Ä±n TensorFlow'u iÃ§e aktarmasÄ±nÄ± engelle (NumPy 2.x ile Ã§akÄ±ÅŸmalarÄ± azaltÄ±r)
os.environ.setdefault("TRANSFORMERS_NO_TF", "1")
os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "3")

from src.models.depth_estimation import MiDaSDepthEstimator
from src.core import CuriosityScorer, CuriosityWeights
from src.utils.image_enhancement import enhance_image_auto
import plotly.express as px
import plotly.graph_objects as go
import cv2
import time
import json

# Matplotlib font ayarlarÄ± - emoji uyarÄ±larÄ±nÄ± Ã¶nlemek iÃ§in
import matplotlib
matplotlib.use('Agg')  # Non-interactive backend
import warnings
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')

# Font ayarlarÄ± - sadece mevcut fontlarÄ± kullan
plt.rcParams['font.family'] = ['DejaVu Sans', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.size'] = 10
plt.rcParams['figure.max_open_warning'] = 0

# Sayfa konfigÃ¼rasyonu
st.set_page_config(
    page_title="ARTPS - Otonom Bilimsel KeÅŸif Sistemi",
    page_icon="ðŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Sahiplik/katkÄ± rozeti (sidebar Ã¼stÃ¼)
st.sidebar.caption("ðŸ›°ï¸ YapÄ±m: [Poyraz BAYDEMÄ°R](https://github.com/Poyqraz) Â· [ResearchGate DOI](http://dx.doi.org/10.13140/RG.2.2.12215.18088)")
st.sidebar.caption("ðŸ“„ Lisans: [MIT License](https://github.com/Poyqraz/ARTPS/blob/main/LICENSE)")

@st.cache_resource
def load_models():
    """EÄŸitilen modelleri yÃ¼kle (cache'li) - GPU Optimizasyonu"""
    
    # GPU kontrolÃ¼
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    st.info(f"ðŸ–¥ï¸ KullanÄ±lan cihaz: {device}")
    
    models = {}
    
    # 1. Autoencoder modeli
    autoencoder_path = "results/optimized_autoencoder_curiosity_extended.pth"
    if os.path.exists(autoencoder_path):
        autoencoder = OptimizedAutoencoder(input_channels=3, latent_dim=1024)
        checkpoint = torch.load(autoencoder_path, map_location=device, weights_only=True)
        autoencoder.load_state_dict(checkpoint['model_state_dict'])
        autoencoder.to(device)  # GPU'ya taÅŸÄ±
        autoencoder.eval()
        models['autoencoder'] = autoencoder
        models['device'] = device
    else:
        st.error(f"âŒ Autoencoder model bulunamadÄ±: {autoencoder_path}")
        return None
    
    # 2. Derinlik geliÅŸtirilmiÅŸ sÄ±nÄ±flandÄ±rÄ±cÄ±
    classifier_path = "results/depth_enhanced_classifier.pth"
    if os.path.exists(classifier_path):
        classifier = DepthEnhancedClassifier(num_classes=5, rgb_features=1024, depth_features=14)
        checkpoint = torch.load(classifier_path, map_location=device, weights_only=True)
        classifier.load_state_dict(checkpoint['model_state_dict'])
        classifier.to(device)  # GPU'ya taÅŸÄ±
        classifier.eval()
        models['classifier'] = classifier
    else:
        st.warning("âš ï¸ SÄ±nÄ±flandÄ±rÄ±cÄ± model bulunamadÄ±, sadece anomali tespiti kullanÄ±lacak")
    
    # 2. PaDiM anomali modeli (opsiyonel)
    try:
        padim_stats = "results/padim_stats.pth"
        padim = PaDiM(PaDiMConfig(image_size=256))
        if Path(padim_stats).exists():
            padim.load(padim_stats)
            models['padim'] = padim
        else:
            st.warning("âš ï¸ PaDiM istatistikleri bulunamadÄ±: results/padim_stats.pth. Sadece AE tabanlÄ± anomali kullanÄ±lacak")
    except Exception as e:
        st.warning(f"âš ï¸ PaDiM yÃ¼klenemedi: {e}")

    # 2b. PatchCore (opsiyonel)
    try:
        patchcore_bank = "results/patchcore_bank.pth"
        if Path(patchcore_bank).exists():
            pcore = PatchCore(PatchCoreConfig(image_size=256))
            pcore.load(patchcore_bank)
            models['patchcore'] = pcore
        else:
            st.info("â„¹ï¸ PatchCore bellek bankasÄ± bulunamadÄ± (tools/prepare_patchcore_bank.py ile Ã¼retebilirsiniz)")
    except Exception as e:
        st.warning(f"âš ï¸ PatchCore yÃ¼klenemedi: {e}")

    # 3. Derinlik tahmin modÃ¼lÃ¼ (gerÃ§ek durumu kontrol et)
    try:
        depth_estimator = MiDaSDepthEstimator(model_type="DPT_Large", device=device)
        
        # GerÃ§ek model durumunu kontrol et
        model_params = sum(p.numel() for p in depth_estimator.model.parameters())
        is_real_dpt = model_params > 100_000_000  # DPT_Large ~345M parametre
        
        if is_real_dpt:
            st.success(f"âœ… DPT_Large modeli baÅŸarÄ±yla yÃ¼klendi (yÃ¼ksek doÄŸruluk) - {model_params:,} parametre")
        else:
            st.warning(f"âš ï¸ DPT_Large modeli yÃ¼klenemedi, basit model kullanÄ±lÄ±yor - {model_params:,} parametre")
            st.info("â„¹ï¸ PyTorch Hub baÄŸlantÄ± sorunu nedeniyle fallback model aktif")
        
        models['depth_estimator'] = depth_estimator
        models['depth_model_info'] = {
            'is_real_dpt': is_real_dpt,
            'param_count': model_params,
            'model_type': depth_estimator.model_type
        }
        
    except Exception as e:
        st.error(f"âŒ Derinlik tahmin modÃ¼lÃ¼ yÃ¼klenemedi: {e}")
    
    # 4. Curiosity skorlayÄ±cÄ± (UI aÄŸÄ±rlÄ±klarÄ±nÄ± daha sonra gÃ¼ncelleyeceÄŸiz)
    models['curiosity_scorer'] = CuriosityScorer(CuriosityWeights())
    # Otomatik: varsa Ã¶ÄŸrenilmiÅŸ aÄŸÄ±rlÄ±klarÄ± yÃ¼kle (bozmadan, sessiz fallback)
    try:
        wpath = Path("results/curiosity_weights.json")
        if wpath.exists():
            with open(wpath, 'r', encoding='utf-8') as f:
                wdata = json.load(f)
            models['curiosity_scorer'] = CuriosityScorer(CuriosityWeights(**wdata))
            st.info("ðŸ§­ Curiosity aÄŸÄ±rlÄ±klarÄ± otomatik yÃ¼klendi (results/curiosity_weights.json)")
    except Exception as e:
        st.warning(f"Curiosity aÄŸÄ±rlÄ±klarÄ± yÃ¼klenemedi: {e}")
    return models

def calculate_anomaly_score(autoencoder, image, device):
    """GÃ¶rÃ¼ntÃ¼ iÃ§in anomali skoru hesapla - GPU Optimizasyonu"""
    
    try:
        # GÃ¶rÃ¼ntÃ¼yÃ¼ iÅŸle
        image = image.resize((128, 128), Image.LANCZOS)
        image_array = np.array(image, dtype=np.float32) / 255.0
        
        # Tensor'a Ã§evir ve GPU'ya taÅŸÄ±
        input_tensor = torch.from_numpy(image_array).float()
        input_tensor = input_tensor.permute(2, 0, 1).unsqueeze(0).to(device)
        
        # Model tahmini (AMP ile hÄ±zlandÄ±rma)
        with torch.no_grad():
            if device.type == 'cuda':
                with torch.amp.autocast('cuda'):
                    reconstructed, latent = autoencoder(input_tensor)
            else:
                reconstructed, latent = autoencoder(input_tensor)
        
        # CPU'ya geri taÅŸÄ± ve numpy'a Ã§evir
        reconstructed = reconstructed.squeeze(0).permute(1, 2, 0).cpu().numpy()
        latent = latent.squeeze().cpu().numpy()
        
        # MSE hesapla (anomali skoru)
        mse = np.mean((image_array - reconstructed) ** 2)
        
        return mse, image_array, reconstructed, latent
        
    except Exception as e:
        st.error(f"âŒ Anomali hesaplama hatasÄ±: {e}")
        return None, None, None, None

def _normalize_map(values: np.ndarray) -> np.ndarray:
    """Harita/yoÄŸunluk matrisini yÃ¼zde 2-98 aralÄ±ÄŸÄ±na gÃ¶re normalize eder (0-1)."""
    arr = values.astype(np.float32)
    lo, hi = np.percentile(arr, 2), np.percentile(arr, 98)
    if hi - lo < 1e-6:
        return np.zeros_like(arr, dtype=np.float32)
    norm = (arr - lo) / (hi - lo)
    return np.clip(norm, 0.0, 1.0)

def _unsharp_image(img: np.ndarray, amount: float = 0.6, radius: float = 2.0) -> np.ndarray:
    """Basit unsharp mask ile keskinleÅŸtirme (uint8 RGB bekler)."""
    try:
        blur = cv2.GaussianBlur(img, (0, 0), radius)
        sharp = cv2.addWeighted(img, 1.0 + amount, blur, -amount, 0)
        return sharp
    except Exception:
        return img

def _safe_imshow(ax, img: np.ndarray, **kwargs) -> None:
    """Matplotlib iÃ§in gÃ¼venli gÃ¶rÃ¼ntÃ¼ Ã§izimi: dtype ve aralÄ±ÄŸÄ± normalize eder.

    - uint8/int32 gibi tiplere karÅŸÄ± dayanÄ±klÄ±
    - float ise [0,1] aralÄ±ÄŸÄ±na sÄ±kÄ±ÅŸtÄ±rÄ±r
    """
    try:
        arr = img
        if isinstance(arr, np.ndarray):
            if arr.dtype not in (np.uint8, np.float32, np.float64, np.int16):
                arr = arr.astype(np.float32)
            if arr.dtype in (np.float32, np.float64):
                # BÃ¼yÃ¼k olasÄ±lÄ±kla [0,1] olmalÄ±
                if arr.max() > 1.0:
                    arr = np.clip(arr / 255.0, 0.0, 1.0)
                else:
                    arr = np.clip(arr, 0.0, 1.0)
            elif arr.dtype == np.uint8:
                # Matplotlib direkt destekler
                pass
            elif arr.dtype == np.int16:
                # KÄ±sa tip: normalize et
                arr = np.clip(arr.astype(np.float32) / 255.0, 0.0, 1.0)
        ax.imshow(arr, **kwargs)
    except Exception:
        # Son Ã§are: gri gÃ¶ster
        ax.imshow(np.zeros((10, 10), dtype=np.float32), cmap='gray')

def _auto_enhance_focus(img_rgb: np.ndarray, scale: float, interp_code: int, amount: float) -> np.ndarray:
    """Odak kÄ±rpÄ±m iÃ§in otomatik kalite artÄ±rma: CLAHE + hafif bilateral + (isteÄŸe baÄŸlÄ±) upsample + unsharp.

    img_rgb: uint8 RGB
    scale: 1.0, 1.5, 2.0 ...
    interp_code: cv2.INTER_*
    amount: unsharp miktarÄ±
    """
    try:
        # Kontrast: LAB'ta CLAHE (L kanalÄ±)
        lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)
        L, A, B = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        L2 = clahe.apply(L)
        lab2 = cv2.merge([L2, A, B])
        img_rgb = cv2.cvtColor(lab2, cv2.COLOR_LAB2RGB)
        # GÃ¼rÃ¼ltÃ¼ azaltÄ±m: hafif bilateral (detayÄ± koru)
        img_rgb = cv2.bilateralFilter(img_rgb, d=3, sigmaColor=25, sigmaSpace=25)
        # Ä°steÄŸe baÄŸlÄ± upsample (keskinleÅŸtirme Ã–NDEN deÄŸil, SONRADAN uygulanÄ±r)
        if float(scale) > 1.0:
            ih, iw = img_rgb.shape[:2]
            img_rgb = cv2.resize(img_rgb, (int(iw * scale), int(ih * scale)), interpolation=interp_code)
        # KeskinleÅŸtirme (son adÄ±m)
        img_rgb = _unsharp_image(img_rgb, amount=max(0.0, float(amount)), radius=1.6)
    except Exception:
        pass
    return img_rgb

def _precompute_focus_tiles(results: dict, detections: list) -> list:
    """SeÃ§im gecikmesini azaltmak iÃ§in odak karolarÄ±nÄ± Ã¶nceden Ã¼retir."""
    try:
        tiles = []
        comb_map = results.get('combined_anomaly_map')
        if comb_map is None or len(detections) == 0:
            return tiles
        H, W = comb_map.shape[:2]
        base = (results['original'] * 255).astype(np.uint8)
        if base.shape[:2] != (H, W):
            base = cv2.resize(base, (W, H), interpolation=cv2.INTER_LINEAR)
        if base.ndim == 2:
            base = cv2.cvtColor(base, cv2.COLOR_GRAY2RGB)
        heat_full = (plt.cm.inferno(comb_map)[..., :3] * 255).astype(np.uint8)
        depth_full = results.get('depth_map_full')

        # Odak ayarlarÄ±
        h_target = int(globals().get('focus_h', 300))
        overlay_mode = bool(globals().get('focus_overlay', True))
        sharpen = bool(globals().get('focus_sharpen', True))
        hide_empty_depth = bool(globals().get('focus_hide_empty_depth', True))
        interp_name = str(globals().get('focus_interp', 'INTER_LANCZOS4'))
        interp = getattr(cv2, interp_name, cv2.INTER_LANCZOS4)

        for det in detections:
            try:
                x, y, w, h = det['x'], det['y'], det['w'], det['h']
                pad = int(0.15 * max(w, h))
                x1 = max(0, x - pad)
                y1 = max(0, y - pad)
                x2 = min(W, x + w + pad)
                y2 = min(H, y + h + pad)
                if (y2 - y1) <= 5 or (x2 - x1) <= 5:
                    tiles.append(None)
                    continue
                # Orijinal kÄ±rpÄ±m
                raw_crop = cv2.cvtColor(base[y1:y2, x1:x2].copy(), cv2.COLOR_BGR2RGB)
                raw_crop = _auto_enhance_focus(raw_crop, scale=1.0, interp_code=interp, amount=0.6)
                # IsÄ± kapaÄŸÄ±
                heat_u8 = heat_full[y1:y2, x1:x2].copy()
                if overlay_mode:
                    if heat_u8.shape[:2] != raw_crop.shape[:2]:
                        heat_u8 = cv2.resize(heat_u8, (raw_crop.shape[1], raw_crop.shape[0]), interpolation=interp)
                    heat_crop = cv2.addWeighted(raw_crop, 0.25, heat_u8, 0.75, 0)
                else:
                    heat_crop = heat_u8
                # Derinlik kenarÄ± karo
                if depth_full is not None and depth_full.shape[:2] == comb_map.shape[:2]:
                    dpatch = depth_full[y1:y2, x1:x2].astype(np.float32)
                    gx = cv2.Sobel(dpatch, cv2.CV_32F, 1, 0, ksize=3)
                    gy = cv2.Sobel(dpatch, cv2.CV_32F, 0, 1, ksize=3)
                    mag = np.sqrt(gx * gx + gy * gy)
                    mag = (mag - mag.min()) / (mag.ptp() + 1e-6)
                    depth_edge_crop = (plt.cm.cividis(mag)[..., :3] * 255).astype(np.uint8)
                else:
                    depth_edge_crop = None
                # KeskinleÅŸtirme
                if sharpen:
                    heat_crop = _unsharp_image(heat_crop, 0.6, 2)
                    if depth_edge_crop is not None:
                        depth_edge_crop = _unsharp_image(depth_edge_crop, 0.6, 2)
                # H yÃ¼ksekliÄŸine yeniden Ã¶rnekle
                def _resize_h(img):
                    ih, iw = img.shape[:2]
                    nw = int(iw * (h_target / max(1, ih)))
                    return cv2.resize(img, (nw, h_target), interpolation=interp)
                # Tespit kutusunu iÅŸaretle
                try:
                    cv2.rectangle(raw_crop, (max(0, pad), max(0, pad)), (max(0, pad) + w, max(0, pad) + h), (240, 220, 0), 1)
                except Exception:
                    pass
                parts = [_resize_h(raw_crop), _resize_h(heat_crop)]
                if depth_edge_crop is not None or not hide_empty_depth:
                    if depth_edge_crop is None:
                        depth_edge_crop = np.zeros_like(heat_crop)
                    parts.append(_resize_h(depth_edge_crop))
                tile = np.concatenate(parts, axis=1)
                tiles.append(tile)
            except Exception:
                tiles.append(None)
        return tiles
    except Exception:
        return []

def compute_combined_anomaly_map(
    original_rgb: np.ndarray,
    reconstructed_rgb: np.ndarray,
    depth_map: np.ndarray,
    *,
    hyst_high_pct: int = 97,
    hyst_low_pct: int = 92,
    nms_iou: float = 0.35,
    top_k: int = 25,
    w_recon: float = 0.50,
    w_depth: float = 0.30,
    w_texture: float = 0.20,
    edge_reinforce: float = 0.35,
):
    """RekonstrÃ¼ksiyon farkÄ± + derinlik sÃ¼reksizliÄŸi + gÃ¶lge/kenar farkÄ±ndalÄ±ÄŸÄ± birleÅŸik haritasÄ±.

    Ek olarak kenar rehberli yeniden keskinleÅŸtirme ve mÃ¼hendislik odaklÄ± kutulama uygular.

    DÃ¶ndÃ¼rÃ¼r: (combined_map[H,W] in 0..1, detections[list of dict])
    """
    # Hedef Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼ derinlik haritasÄ± boyutu
    H, W = depth_map.shape[:2]
    orig = cv2.resize(original_rgb.astype(np.float32), (W, H), interpolation=cv2.INTER_AREA)
    recon = cv2.resize(reconstructed_rgb.astype(np.float32), (W, H), interpolation=cv2.INTER_AREA)

    # RekonstrÃ¼ksiyon farkÄ± (MSE kanal baÅŸÄ±na)
    recon_diff = ((orig - recon) ** 2).mean(axis=2)
    recon_diff_n = _normalize_map(recon_diff)

    # GÃ¶rÃ¼ntÃ¼ gri, kenar/kontrast ve gÃ¶lge gÃ¶stergesi
    img_u8 = (orig * 255.0).astype(np.uint8)
    gray = cv2.cvtColor(img_u8, cv2.COLOR_RGB2GRAY).astype(np.float32) / 255.0
    hsv = cv2.cvtColor(img_u8, cv2.COLOR_RGB2HSV).astype(np.float32) / 255.0
    Hc, Sc, Vc = hsv[..., 0], hsv[..., 1], hsv[..., 2]
    sobelx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)
    sobely = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)
    grad_mag = np.sqrt(sobelx ** 2 + sobely ** 2)
    grad_mag_n = _normalize_map(grad_mag)
    shadow_n = _normalize_map(1.0 - gray)  # koyu bÃ¶lgeler yÃ¼ksek

    # Derinlik sÃ¼reksizliÄŸi ve yakÄ±nlÄ±k aÄŸÄ±rlÄ±ÄŸÄ±
    depth = depth_map.astype(np.float32)
    depth_n_for_region = _normalize_map(depth)
    dx = cv2.Sobel(depth, cv2.CV_32F, 1, 0, ksize=3)
    dy = cv2.Sobel(depth, cv2.CV_32F, 0, 1, ksize=3)
    depth_edge = np.sqrt(dx ** 2 + dy ** 2)
    depth_edge_n = _normalize_map(depth_edge)
    proximity_w = _normalize_map(1.0 - depth)  # yakÄ±n bÃ¶lgeler yÃ¼ksek aÄŸÄ±rlÄ±k

    # Derinlik Laplacian (Ã§Ã¶kÃ¼ntÃ¼/Ã§Ä±kÄ±ntÄ± vurgusu)
    depth_lap = cv2.Laplacian(depth, cv2.CV_32F, ksize=3)
    depth_lap_n = _normalize_map(np.abs(depth_lap))

    # BirleÅŸik skor (ayarlanabilir aÄŸÄ±rlÄ±klar)
    # Not: GÃ¶lge bÃ¶lgeleri sahte anomaliye yol aÃ§abildiÄŸinden, texture_term
    # doÄŸrudan gÃ¶lgeyi yÃ¼kseltmek yerine kenar aÄŸÄ±rlÄ±klÄ± tutulur.
    texture_term = 0.35 * shadow_n + 0.65 * grad_mag_n
    # Laplacian katkÄ±sÄ± UI'dan gelebilir; yoksa 0.08 varsay
    w_lap = float(globals().get('w_lap', 0.08))
    # Ä°nce detay vurgusu (kÃ¼Ã§Ã¼k taÅŸ, kum hatlarÄ± iÃ§in): Ã§ok Ã¶lÃ§ekli Laplacian + DoG
    try:
        lap3 = cv2.Laplacian(gray, cv2.CV_32F, ksize=3)
        lap5 = cv2.Laplacian(gray, cv2.CV_32F, ksize=5)
        dog = cv2.GaussianBlur(gray, (0, 0), 0.8) - cv2.GaussianBlur(gray, (0, 0), 1.6)
        fine_detail = _normalize_map(np.abs(lap3) + 0.6 * np.abs(lap5) + 0.8 * np.abs(dog))
    except Exception:
        fine_detail = np.zeros_like(recon_diff_n)

    w_detail = float(globals().get('w_detail', 0.12))
    raw_combined = (
        w_recon * recon_diff_n
        + w_depth * depth_edge_n
        + w_texture * texture_term
        + w_lap * depth_lap_n
        + w_detail * fine_detail
    )
    # YakÄ±nlÄ±k aÄŸÄ±rlÄ±ÄŸÄ±: uzak alanlarÄ± tamamen bastÄ±rmamak iÃ§in karÄ±ÅŸÄ±m uygula
    proximity_mix = 0.65 * proximity_w + 0.35 * (1.0 - proximity_w)
    combined = np.clip(raw_combined * (0.5 + 0.5 * proximity_mix), 0.0, 1.0)

    # GÃ¶lge bastÄ±rma: (koyu) AND (dÃ¼ÅŸÃ¼k gÃ¶rÃ¼ntÃ¼ gradyanÄ±) AND (dÃ¼ÅŸÃ¼k derinlik kenarÄ±)
    # ve aydÄ±nlatma-kenar etkisi azaltÄ±mÄ±: gÃ¶rÃ¼ntÃ¼ kenarÄ± yÃ¼ksek ama derinlik kenarÄ± dÃ¼ÅŸÃ¼kse etkisini dÃ¼ÅŸÃ¼r.
    try:
        illumination_edge = np.clip(grad_mag_n - depth_edge_n, 0.0, 1.0)
        shadow_like = np.clip(shadow_n * (1.0 - grad_mag_n) * (1.0 - depth_edge_n), 0.0, 1.0)
        shadow_like = cv2.GaussianBlur(shadow_like, (5, 5), 0)
        # SpekÃ¼ler/parlak nokta maskesi: yÃ¼ksek V, dÃ¼ÅŸÃ¼k S ve dÃ¼ÅŸÃ¼k kenar
        spec_mask = np.clip(Vc * (1.0 - Sc) * (1.0 - grad_mag_n) * (1.0 - depth_edge_n), 0.0, 1.0)
        spec_mask = cv2.GaussianBlur(spec_mask, (3, 3), 0)
        # DÃ¼ÅŸÃ¼k doku (varyans) haritasÄ±: kÃ¼Ã§Ã¼k pencere varyansÄ±
        gray_f32 = gray.astype(np.float32)
        k = 5
        mean = cv2.boxFilter(gray_f32, ddepth=-1, ksize=(k, k), normalize=True)
        mean_sq = cv2.boxFilter(gray_f32 * gray_f32, ddepth=-1, ksize=(k, k), normalize=True)
        variance = np.clip(mean_sq - mean * mean, 0.0, 1.0)
        var_norm = variance / max(variance.max(), 1e-6)

        # Saha ayarlÄ± katsayÄ±lar
        alpha_shad = float(globals().get('alpha_shad', 0.65))
        beta_illum = float(globals().get('beta_illum', 0.25))
        spec_gamma = float(globals().get('spec_gamma', 0.35))
        spec_lowvar_gamma = float(globals().get('spec_lowvar_gamma', 0.35))
        spec_var_thresh = float(globals().get('spec_var_thresh', 0.005))
        # DÃ¼ÅŸÃ¼k varyans bÃ¶lgeleri iÃ§in ek azaltÄ±m (spekÃ¼ler dÃ¼z alanlar)
        lowvar_mask = (var_norm < spec_var_thresh).astype(np.float32)
        lowvar_mask = cv2.GaussianBlur(lowvar_mask, (3, 3), 0)
        combined = np.clip(
            combined * (1.0 - alpha_shad * shadow_like)
            - beta_illum * illumination_edge
            - spec_gamma * spec_mask
            - spec_lowvar_gamma * lowvar_mask,
            0.0,
            1.0,
        )
    except Exception:
        pass

    # Kenar rehberli yeniden keskinleÅŸtirme (overlay ve kutu netliÄŸi iÃ§in)
    try:
        guide_u8 = (orig * 255.0).astype(np.uint8)
        guide_gray = cv2.cvtColor(guide_u8, cv2.COLOR_RGB2GRAY)
        if hasattr(cv2, 'ximgproc') and hasattr(cv2.ximgproc, 'jointBilateralFilter'):
            joint = cv2.ximgproc.jointBilateralFilter(guide_gray, (combined * 255).astype(np.uint8), d=9, sigmaColor=25, sigmaSpace=25)
            combined = joint.astype(np.float32) / 255.0
        else:
            combined = cv2.bilateralFilter((combined * 255).astype(np.uint8), d=9, sigmaColor=25, sigmaSpace=25).astype(np.float32) / 255.0
        # Guided filter ile hizalama (varsa)
        if hasattr(cv2, 'ximgproc') and hasattr(cv2.ximgproc, 'guidedFilter'):
            gf = cv2.ximgproc.guidedFilter(guide_u8, (combined * 255).astype(np.uint8), radius=8, eps=1e-2)
            combined = gf.astype(np.float32) / 255.0
        # Unsharp mask + kenar vurgusu
        edges = cv2.Canny(guide_gray, 50, 150).astype(np.float32) / 255.0
        combined = np.clip(combined + edge_reinforce * (edges * (combined - cv2.GaussianBlur(combined, (0, 0), 1.0))), 0.0, 1.0)
    except Exception:
        combined = cv2.GaussianBlur(combined, (3, 3), 0.0)

    # Histerezis eÅŸikleme ile aday bÃ¶lgeler (seed-grow): daha saÄŸlam tespit
    high_th = float(np.percentile(combined, hyst_high_pct))
    low_th = float(np.percentile(combined, hyst_low_pct))
    high_mask = (combined >= high_th).astype(np.uint8)
    low_mask = (combined >= low_th).astype(np.uint8)

    # Seed'leri dÃ¼ÅŸÃ¼k eÅŸik alanÄ±nda geniÅŸlet (yaklaÅŸÄ±k morfolojik rekonstrÃ¼ksiyon)
    kernel = np.ones((3, 3), np.uint8)
    prev = np.zeros_like(high_mask)
    seeds = (high_mask * 255).astype(np.uint8)
    low = (low_mask * 255).astype(np.uint8)
    for _ in range(10):
        dil = cv2.dilate(seeds, kernel, iterations=1)
        seeds = cv2.bitwise_and(dil, low)
        if np.array_equal(seeds, prev):
            break
        prev = seeds.copy()
    mask = seeds
    # Temizleme ve doldurma
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8))

    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    detections = []
    area_min_pct = float(globals().get('min_area_pct', 0.10)) / 100.0
    area_min = max(1.0, area_min_pct * H * W)
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        # BÃ¶lge sÄ±nÄ±rlarÄ±nÄ± gÃ¼venli kÄ±rp
        y1c, y2c = max(0, y), min(H, y + h)
        x1c, x2c = max(0, x), min(W, x + w)
        # Uzak alanlar iÃ§in daha kÃ¼Ã§Ã¼k eÅŸik: derinlik yÃ¼ksekse alan eÅŸiÄŸini dÃ¼ÅŸÃ¼r
        region_depth_mean = float(np.mean(depth_n_for_region[y1c:y2c, x1c:x2c])) if (y2c > y1c and x2c > x1c) else 0.0
        local_area_min = area_min * (0.35 + 0.65 * (1.0 - region_depth_mean))
        if cv2.contourArea(cnt) < local_area_min:
            continue
        # DÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸ dikdÃ¶rtgen (daha sÄ±kÄ± kutulama)
        rect = cv2.minAreaRect(cnt)
        box_pts = cv2.boxPoints(rect)
        box_pts = np.int0(box_pts)
        # BÃ¶lge sÄ±nÄ±rlarÄ±nÄ± gÃ¼venli kÄ±rp
        y1, y2 = y1c, y2c
        x1, x2 = x1c, x2c
        region = combined[y1:y2, x1:x2]
        region_edges = grad_mag_n[y1:y2, x1:x2]
        region_shadow = shadow_like[y1:y2, x1:x2] if 'shadow_like' in locals() else None
        region_illum = illumination_edge[y1:y2, x1:x2] if 'illumination_edge' in locals() else None
        region_spec = spec_mask[y1:y2, x1:x2] if 'spec_mask' in locals() else None
        region_prox = proximity_w[y1:y2, x1:x2]
        # YakÄ±nlÄ±k ortalamasÄ±
        prox_mean = float(np.mean(region_prox)) if region_prox.size else 0.0
        # BÃ¶lge skorlarÄ±
        comb_mean = float(np.mean(region)) if region.size else 0.0
        edge_mean = float(np.mean(region_edges)) if region_edges.size else 0.0
        # GÃ¶lge ve aydÄ±nlatma-kenarÄ± azaltÄ±mlarÄ±
        shadow_pen = float(np.mean(region_shadow)) if (region_shadow is not None and region_shadow.size) else 0.0
        illum_pen = float(np.mean(region_illum)) if (region_illum is not None and region_illum.size) else 0.0
        spec_pen = float(np.mean(region_spec)) if (region_spec is not None and region_spec.size) else 0.0
        lowvar_pen = float(np.mean(lowvar_mask[y1:y2, x1:x2])) if 'lowvar_mask' in locals() else 0.0
        # Uzak alanlar iÃ§in kÃ¼Ã§Ã¼k ayrÄ±ntÄ±larÄ± daha iyi puanlamak adÄ±na fine_detail katkÄ±sÄ±nÄ± ekle
        fine_local = float(np.mean(fine_detail[y1:y2, x1:x2])) if (y2 > y1 and x2 > x1) else 0.0
        score = 0.5 * comb_mean + 0.25 * edge_mean + 0.2 * prox_mean + 0.05 * fine_local - 0.35 * shadow_pen - 0.20 * illum_pen - 0.30 * spec_pen - 0.25 * lowvar_pen
        score = float(max(0.0, score))

        # Saf gÃ¶lge veya spekÃ¼ler bÃ¶lgeleri ele: saha ayarlÄ± eÅŸikler
        sh_cut = float(globals().get('shadow_cut', 0.45))
        im_edge_min = float(globals().get('img_edge_min', 0.10))
        dp_edge_min = float(globals().get('depth_edge_min', 0.08))
        sp_cut = float(globals().get('spec_cut', 0.50))
        if shadow_pen > sh_cut and edge_mean < im_edge_min and float(np.mean(depth_edge_n[y1:y2, x1:x2])) < dp_edge_min:
            continue
        if spec_pen > sp_cut and edge_mean < im_edge_min and float(np.mean(depth_edge_n[y1:y2, x1:x2])) < dp_edge_min:
            continue
        # Ã‡ok dÃ¼ÅŸÃ¼k doku + (dÃ¼ÅŸÃ¼k kenar) bÃ¶lgeleri de ele (tek piksel parlamalarÄ±)
        if lowvar_pen > 0.6 and edge_mean < im_edge_min:
            continue
        detections.append({
            "x": int(x), "y": int(y), "w": int(w), "h": int(h),
            "score": float(score),
            "poly": box_pts.tolist(),
            # aÃ§Ä±klayÄ±cÄ± metrikler (debug/ince ayar iÃ§in)
            "comb_mean": float(comb_mean),
            "edge_mean": float(edge_mean),
            "prox_mean": float(prox_mean),
            "shadow_pen": float(shadow_pen),
            "illum_pen": float(illum_pen),
            "spec_pen": float(spec_pen),
            "lowvar_pen": float(lowvar_pen) if 'lowvar_pen' in locals() else 0.0,
        })

    # Non-Maximum Suppression (IoU tabanlÄ±) ile kutularÄ± rafine et
    def _iou(a, b):
        ax1, ay1, aw, ah = a[0], a[1], a[2], a[3]
        bx1, by1, bw, bh = b[0], b[1], b[2], b[3]
        ax2, ay2 = ax1 + aw, ay1 + ah
        bx2, by2 = bx1 + bw, by1 + bh
        inter_x1, inter_y1 = max(ax1, bx1), max(ay1, by1)
        inter_x2, inter_y2 = min(ax2, bx2), min(ay2, by2)
        iw, ih = max(0, inter_x2 - inter_x1), max(0, inter_y2 - inter_y1)
        inter = iw * ih
        union = aw * ah + bw * bh - inter + 1e-6
        return inter / union

    detections = sorted(detections, key=lambda d: d["score"], reverse=True)
    kept = []
    for det in detections:
        if all(_iou((det['x'], det['y'], det['w'], det['h']), (k['x'], k['y'], k['w'], k['h'])) < nms_iou for k in kept):
            kept.append(det)
    detections = kept[:max(1, int(top_k))]

    # YakÄ±n kutularÄ± birleÅŸtir (merkez yakÄ±n ve IoU dÃ¼ÅŸÃ¼kse tek kutu yap)
    try:
        miou = float(globals().get('merge_iou', 0.15))
        mtol = float(globals().get('merge_tol', 0.5))
        merged = []
        used = [False] * len(detections)
        diag = float(np.hypot(W, H))
        for i, a in enumerate(detections):
            if used[i]:
                continue
            axc = a['x'] + a['w'] / 2.0
            ayc = a['y'] + a['h'] / 2.0
            group = [i]
            for j, b in enumerate(detections[i + 1:], start=i + 1):
                if used[j]:
                    continue
                iou_ab = _iou((a['x'], a['y'], a['w'], a['h']), (b['x'], b['y'], b['w'], b['h']))
                bxc = b['x'] + b['w'] / 2.0
                byc = b['y'] + b['h'] / 2.0
                center_dist = np.hypot(axc - bxc, ayc - byc)
                if iou_ab < miou and center_dist < mtol * diag * 0.02:
                    group.append(j)
                    used[j] = True
            # GruplarÄ± tek kutuya birleÅŸtir
            xs = [detections[g]['x'] for g in group]
            ys = [detections[g]['y'] for g in group]
            ws = [detections[g]['w'] for g in group]
            hs = [detections[g]['h'] for g in group]
            x1 = int(min(xs))
            y1 = int(min(ys))
            x2 = int(max(xs[k] + ws[k] for k in range(len(xs))))
            y2 = int(max(ys[k] + hs[k] for k in range(len(ys))))
            region = combined[y1:y2, x1:x2]
            merged.append({
                'x': x1, 'y': y1, 'w': x2 - x1, 'h': y2 - y1,
                'score': float(region.mean()) if region.size else a['score'],
                'poly': None
            })
            used[i] = True
        detections = merged
    except Exception:
        pass

    # Ufuk maskesi: derin ve dÃ¼ÅŸÃ¼k gradyan alanlarÄ± (genelde Ã¼st kÄ±sÄ±m)
    try:
        horizon_mask = ((depth > 0.8) & (depth_edge_n < 0.05)).astype(np.uint8)
        # Ufuk bilgisi raporlama iÃ§in; kombinasyondan Ã§Ä±karmÄ±yoruz ama metrik olabilir
    except Exception:
        horizon_mask = None

    return combined.astype(np.float32), detections

def calculate_known_value_score(classifier, depth_estimator, image_array, latent_features, device):
    """Dinamik bilinen deÄŸer skoru hesapla - GPU Optimizasyonu"""
    
    try:
        # Derinlik tahmini
        depth_map, depth_metadata = depth_estimator.estimate_depth(image_array)
        
        # Derinlik Ã¶zelliklerini Ã§Ä±kar
        depth_features = depth_estimator.extract_depth_features(depth_map)
        # EÄŸitimde kullanÄ±lan 14 Ã¶zellik dizilimi (sabit sÄ±ra)
        depth_feature_keys = [
            'depth_mean', 'depth_std', 'depth_min', 'depth_max',
            'depth_median', 'depth_percentile_25', 'depth_percentile_75',
            'depth_variance', 'depth_skewness', 'depth_kurtosis',
            'surface_complexity', 'depth_gradient_mean', 'depth_gradient_std', 'depth_gradient_max',
        ]
        depth_vec = [float(depth_features.get(k, 0.0)) for k in depth_feature_keys]
        depth_features_tensor = torch.tensor(depth_vec, dtype=torch.float32).unsqueeze(0).to(device)
        
        # RGB latent features
        rgb_features_tensor = torch.tensor(latent_features, dtype=torch.float32).unsqueeze(0).to(device)
        
        # SÄ±nÄ±flandÄ±rma tahmini (AMP)
        with torch.no_grad():
            if device.type == 'cuda':
                with torch.amp.autocast('cuda'):
                    predictions = classifier(rgb_features_tensor, depth_features_tensor)
            else:
                predictions = classifier(rgb_features_tensor, depth_features_tensor)
            predicted_class = torch.argmax(predictions, dim=1).item()
            confidence = torch.max(predictions).item()
        
        # SÄ±nÄ±f deÄŸerlerini normalize et (0-1 arasÄ±)
        value_score = predicted_class / 4.0  # 0-4 arasÄ± sÄ±nÄ±flarÄ± 0-1 arasÄ±na Ã§evir
        
        return value_score, confidence, predicted_class, depth_map, depth_features
        
    except Exception as e:
        st.warning(f"âš ï¸ Bilinen deÄŸer hesaplama hatasÄ±: {e}")
        return 0.5, 0.0, 2, None, {}  # Fallback deÄŸerler

def analyze_mars_image(models, image):
    """Mars gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ kapsamlÄ± analiz et - GPU Optimizasyonu"""
    
    # Son analiz sonuÃ§larÄ±nÄ± yeniden Ã§alÄ±ÅŸtÄ±rmada kaybetmemek iÃ§in session_state'ten Ã§ek
    results = st.session_state.get("results", {})
    device = models.get('device', torch.device('cpu'))
    
    # 1. Anomali skoru hesapla
    mse, original, reconstructed, latent = calculate_anomaly_score(models['autoencoder'], image, device)
    results['anomaly_score'] = mse
    results['original'] = original
    results['reconstructed'] = reconstructed
    results['latent'] = latent
    
    # 2. Bilinen deÄŸer skoru hesapla (hibrit model varsa)
    if 'classifier' in models and 'depth_estimator' in models:
        value_score, confidence, predicted_class, depth_map, depth_features = calculate_known_value_score(
            models['classifier'], models['depth_estimator'], original, latent, device
        )
        results['known_value_score'] = value_score
        results['confidence'] = confidence
        results['predicted_class'] = predicted_class
        results['depth_map'] = depth_map
        results['depth_features'] = depth_features
    else:
        # Fallback: Sabit deÄŸer
        results['known_value_score'] = 0.5
        results['confidence'] = 0.0
        results['predicted_class'] = 2
        results['depth_map'] = None
        results['depth_features'] = {}
    
    # 3. Derinlik mevcutsa, gÃ¶rÃ¼ntÃ¼ + derinlik tabanlÄ± birleÅŸik anomali haritasÄ± Ã¼ret
    try:
        depth_map_for_fusion = None
        if 'depth_estimator' in models:
            depth_input_res = 768
            image_for_depth = np.array(image.resize((depth_input_res, depth_input_res), Image.LANCZOS), dtype=np.float32) / 255.0
            try:
                depth_map_for_fusion, _ = models['depth_estimator'].estimate_depth(
                    image_for_depth,
                    apply_enhancement=True,
                    high_detail=True,
                    tta_flips=True,
                    use_fgs=True,
                    use_wmf=True,
                )
            except Exception:
                depth_map_for_fusion = None

        # Derinlik baÅŸarÄ±sÄ±z olursa, gradient tabanlÄ± sentetik derinlik Ã¼ret (fallback)
        if depth_map_for_fusion is None:
            img_u8 = (results['original'] * 255.0).astype(np.uint8)
            gray = cv2.cvtColor(img_u8, cv2.COLOR_RGB2GRAY).astype(np.float32) / 255.0
            sx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)
            sy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)
            grad = np.sqrt(sx * sx + sy * sy)
            depth_map_for_fusion = _normalize_map(1.0 - grad)  # kenar alanlarÄ± uzak, dÃ¼z alanlar yakÄ±n
            results['depth_map_full'] = depth_map_for_fusion
        else:
            results['depth_map_full'] = depth_map_for_fusion

        # BirleÅŸik anomali haritasÄ± hesapla (her durumda)
        # UI'dan ayarlar mevcutsa kullan; yoksa varsayÄ±lanlar
        cfg_hh = int(globals().get('hyst_high', 97))
        cfg_hl = int(globals().get('hyst_low', 92))
        cfg_nms = float(globals().get('nms_iou', 0.35))
        cfg_topk = int(globals().get('top_k', 25))
        cfg_wr = float(globals().get('w_recon', 0.50))
        cfg_wd = float(globals().get('w_depth', 0.30))
        cfg_wt = float(globals().get('w_texture', 0.20))
        cfg_er = float(globals().get('edge_reinf', 0.35))

        combined_map, detections = compute_combined_anomaly_map(
            results['original'], results['reconstructed'], depth_map_for_fusion,
            hyst_high_pct=cfg_hh, hyst_low_pct=cfg_hl, nms_iou=cfg_nms, top_k=cfg_topk,
            w_recon=cfg_wr, w_depth=cfg_wd, w_texture=cfg_wt, edge_reinforce=cfg_er
        )
        # PaDiM/PatchCore mevcutsa, haritalarÄ± yumuÅŸak birleÅŸtir
        try:
            base_u8 = (results['original'] * 255).astype(np.uint8)
            if 'padim' in models:
                padim_map = models['padim'].predict_anomaly_map(base_u8)
                padim_w = float(globals().get('w_padim', 0.30))
                combined_map = np.clip((1.0 - padim_w) * combined_map + padim_w * padim_map, 0.0, 1.0)
            if 'patchcore' in models:
                pcore_map = models['patchcore'].predict_anomaly_map(base_u8)
                pcore_w = float(globals().get('w_patchcore', 0.25))
                combined_map = np.clip((1.0 - pcore_w) * combined_map + pcore_w * pcore_map, 0.0, 1.0)
        except Exception:
            pass
        results['combined_anomaly_map'] = combined_map
        results['combined_anomaly_score'] = float(combined_map.mean())
        results['detections'] = detections
        # Odak karo Ã¶nbelleÄŸi: hÄ±zlÄ± seÃ§im gecikmesini azalt
        try:
            results['focus_tiles'] = _precompute_focus_tiles(results, detections)
        except Exception:
            results['focus_tiles'] = []
    except Exception:
        # Son Ã§are: yalnÄ±zca fark haritasÄ±na dayalÄ± basit tespit
        diff_only = ((results['original'] - results['reconstructed']) ** 2).mean(axis=2)
        diff_only = _normalize_map(diff_only)
        results['combined_anomaly_map'] = diff_only
        results['combined_anomaly_score'] = float(diff_only.mean())
        # Basit eÅŸik + kontur
        th = float(np.percentile(diff_only, 97))
        mask = (diff_only >= th).astype(np.uint8) * 255
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        detections = []
        H, W = diff_only.shape[:2]
        area_min = 0.001 * H * W
        for c in contours:
            if cv2.contourArea(c) < area_min:
                continue
            x, y, w, h = cv2.boundingRect(c)
            detections.append({"x": int(x), "y": int(y), "w": int(w), "h": int(h), "score": float(diff_only[y:y+h, x:x+w].mean())})
        results['detections'] = detections
        try:
            results['focus_tiles'] = _precompute_focus_tiles(results, detections)
        except Exception:
            results['focus_tiles'] = []
    
    # 4. Curiosity skoru: tek yerden, seÃ§ilebilir bileÅŸenlerle hesapla
    try:
        scorer = models.get('curiosity_scorer')
        if scorer is not None:
            # UI'dan aÄŸÄ±rlÄ±klarÄ± Ã§ek (globals, sidebar iÃ§inde set edildi)
            cw = CuriosityWeights(
                w_known=float(globals().get('alpha', 0.4)),
                w_anomaly=float(globals().get('beta', 0.6)),
                w_combined=float(globals().get('w_combined', 0.0)),
                w_depth_variance=float(globals().get('w_dvar', 0.0)),
                w_roughness=float(globals().get('w_rough', 0.0)),
            )
            models['curiosity_scorer'] = CuriosityScorer(cw)
            score, breakdown = models['curiosity_scorer'].compute(
                known_value_score=results.get('known_value_score'),
                anomaly_mse=results.get('anomaly_score'),
                combined_anomaly_score=results.get('combined_anomaly_score'),
                depth_features=results.get('depth_features'),
                reference_mse=float(globals().get('ref_mse', 0.003)),
            )
            results['curiosity_score'] = float(score)
            results['curiosity_breakdown'] = breakdown
    except Exception:
        pass

    return results

def main():
    """Ana uygulama"""
    
    # BaÅŸlÄ±k
    st.title("ðŸš€ ARTPS - Otonom Bilimsel KeÅŸif Sistemi")
    st.markdown("**Mars Rover'larÄ± iÃ§in Hibrit AI Sistemi (Derinlik + Dinamik DeÄŸer)**")
    
    # Sidebar
    st.sidebar.header("ðŸŽ›ï¸ Kontrol Paneli")
    
    # Modelleri yÃ¼kleme
    with st.spinner("ðŸ¤– Hibrit modeller yÃ¼kleniyor..."):
        models = load_models()
    
    if models is None:
        st.error("âŒ Modeller yÃ¼klenemedi! LÃ¼tfen model dosyalarÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol edin.")
        return
    
    # Model durumu
    model_status = []
    if 'autoencoder' in models:
        model_status.append("âœ… Autoencoder")
    if 'classifier' in models:
        model_status.append("âœ… Hibrit SÄ±nÄ±flandÄ±rÄ±cÄ±")
    if 'depth_estimator' in models:
        depth_model_info = models['depth_model_info']
        model_status.append(f"âœ… Derinlik Tahmini ({depth_model_info['model_type']}) - {'YÃ¼ksek DoÄŸruluk' if depth_model_info['is_real_dpt'] else 'Basit Model'}")
    if 'padim' in models:
        model_status.append("âœ… PaDiM (Anomali FÃ¼zyon)")
    if 'patchcore' in models:
        model_status.append("âœ… PatchCore (Anomali FÃ¼zyon)")
    # Derinlik modeli durumunu detaylÄ± gÃ¶ster
    if 'depth_model_info' in models:
        info = models['depth_model_info']
        st.sidebar.info(
            f"Aktif Derinlik Modeli: {info.get('model_type','?')} â€” Parametre: {info.get('param_count',0):,} â€” "
            + ("YÃ¼ksek DoÄŸruluk" if info.get('is_real_dpt') else "Basit/Fallback")
        )
    
    st.sidebar.success(f"Modeller yÃ¼klendi:\n" + "\n".join(model_status))
    
    # Parametre ayarlarÄ±
    st.sidebar.subheader("ðŸ“Š Parametre AyarlarÄ±")
    
    alpha = st.sidebar.slider(
        "Î± (Alfa) - Bilinen DeÄŸer AÄŸÄ±rlÄ±ÄŸÄ±", 0.0, 1.0, 0.4, 0.1,
        help="Curiosity skorunda sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n tahmin ettiÄŸi 'bilinen deÄŸer' katkÄ±sÄ±. YÃ¼ksek olduÄŸunda bilinen bilimsel aÃ§Ä±dan deÄŸerli sÄ±nÄ±flara benzer gÃ¶rÃ¼ntÃ¼ler daha Ã§ok Ã¶ne Ã§Ä±kar."
    )
    beta = st.sidebar.slider(
        "Î² (Beta) - Anomali AÄŸÄ±rlÄ±ÄŸÄ±", 0.0, 1.0, 0.6, 0.1,
        help="Curiosity skorunda AE tabanlÄ± anomali MSE katkÄ±sÄ±. YÃ¼ksek olduÄŸunda beklenmedik/dÃ¼zensiz yapÄ±lar daha Ã§ok Ã¶ne Ã§Ä±kar."
    )
    w_combined = st.sidebar.slider(
        "w_combined (BirleÅŸik Anomali)", 0.0, 1.0, 0.0, 0.05,
        help="BirleÅŸik anomali haritasÄ±nÄ±n ortalama yoÄŸunluÄŸunun curiosity skoruna katkÄ±sÄ±. AE farkÄ±, derinlik kenarÄ± ve doku bileÅŸenlerinden oluÅŸur."
    )
    w_dvar = st.sidebar.slider(
        "w_depth_variance", 0.0, 1.0, 0.0, 0.05,
        help="Derinlik varyansÄ±nÄ±n (3B yapÄ± Ã§eÅŸitliliÄŸi) curiosity skoruna katkÄ±sÄ±. YÃ¼ksek varyans, daha karmaÅŸÄ±k jeomorfoloji anlamÄ±na gelebilir."
    )
    w_rough = st.sidebar.slider(
        "w_roughness", 0.0, 1.0, 0.0, 0.05,
        help="PÃ¼rÃ¼zlÃ¼lÃ¼k (gradyan ve laplace deÄŸiÅŸkenliÄŸi) katkÄ±sÄ±. KÃ¼Ã§Ã¼k taÅŸ/kum Ã§izgileri gibi ince detaylarÄ± Ã¶ne Ã§Ä±karabilir."
    )
    
    anomaly_threshold = st.sidebar.slider(
        "Anomali EÅŸiÄŸi",
        min_value=0.0,
        max_value=0.01,
        value=0.003,
        step=0.0001,
        help="AE MSE iÃ§in karar eÅŸiÄŸi. Bu eÅŸik Ã¼stÃ¼ deÄŸerler tek baÅŸÄ±na 'anormal' kabul edilebilir."
    )
    ref_mse = st.sidebar.slider(
        "Curiosity Referans MSE",
        min_value=0.0005,
        max_value=0.02,
        value=0.003,
        step=0.0001,
        help="Curiosity normalizasyonu iÃ§in AE MSE referansÄ±. YaklaÅŸÄ±k olarak 2Ã—ref MSE â†’ 1.0 skora sÄ±kÄ±ÅŸtÄ±rÄ±lÄ±r."
    )

    # AÄŸÄ±rlÄ±klarÄ± global deÄŸiÅŸkenlere atayarak analiz fonksiyonuna geÃ§iriyoruz
    globals()['alpha'] = alpha
    globals()['beta'] = beta
    globals()['w_combined'] = w_combined
    globals()['w_dvar'] = w_dvar
    globals()['w_rough'] = w_rough
    globals()['anomaly_threshold'] = anomaly_threshold
    globals()['ref_mse'] = ref_mse

    with st.sidebar.expander("ðŸ”§ Tespit AyarlarÄ± (GeliÅŸmiÅŸ)", expanded=False):
        unified_threshold = st.slider("BirleÅŸik Anomali EÅŸiÄŸi", 0.0, 1.0, 0.60, 0.01)
        col_adv1, col_adv2 = st.columns(2)
        with col_adv1:
            hyst_high = st.slider("Histerezis High (%)", 90, 99, 96, 1)
        with col_adv2:
            hyst_low = st.slider("Histerezis Low (%)", 85, 98, 90, 1)
        nms_iou = st.slider("NMS IoU", 0.10, 0.70, 0.25, 0.01)
        top_k = st.number_input("Top-K Kutu", min_value=5, max_value=100, value=25, step=1)
        min_area_pct = st.slider("Min Kutu AlanÄ± (%)", 0.01, 2.00, 0.10, 0.01, help="GÃ¶rÃ¼ntÃ¼ alanÄ±na gÃ¶re")
        with st.expander("AÄŸÄ±rlÄ±klar", expanded=False):
            w_recon = st.slider("w_recon (fark)", 0.0, 1.0, 0.50, 0.05)
            w_depth = st.slider("w_depthEdge (âˆ‡depth)", 0.0, 1.0, 0.30, 0.05)
            w_texture = st.slider("w_texture (gÃ¶lge+kenar)", 0.0, 1.0, 0.20, 0.05)
            w_lap = st.slider("w_lap (Î” depth)", 0.0, 0.5, 0.08, 0.01)
            edge_reinf = st.slider("edge reinforce", 0.0, 1.0, 0.40, 0.05)
            w_detail = st.slider("w_detail (ince detay)", 0.0, 0.5, 0.12, 0.01, help="KÃ¼Ã§Ã¼k taÅŸ/kum Ã§izgilerini vurgulayan Ã§ok Ã¶lÃ§ekli detay bileÅŸeni")
            w_padim = st.slider("w_padim (PaDiM fÃ¼zyon)", 0.0, 1.0, 0.30, 0.05, help="PaDiM anomali haritasÄ±nÄ±n birleÅŸik haritaya katkÄ±sÄ±")
            w_patchcore = st.slider("w_patchcore (PatchCore fÃ¼zyon)", 0.0, 1.0, 0.25, 0.05, help="PatchCore anomali haritasÄ±nÄ±n birleÅŸik haritaya katkÄ±sÄ±")
        with st.expander("Kutu BirleÅŸtirme", expanded=False):
            merge_iou = st.slider("BirleÅŸtirme IoU", 0.0, 0.8, 0.15, 0.01)
            merge_tol = st.slider("Merkez YakÄ±nlÄ±k (diagonal oranÄ±)", 0.1, 1.5, 0.5, 0.05)
            st.caption("YakÄ±n kÃ¼Ã§Ã¼k kutularÄ± birleÅŸik hedefe toplar; uzak alandaki kÃ¼Ã§Ã¼k detaylar iÃ§in daha dÃ¼ÅŸÃ¼k IoU ile koruma saÄŸlar.")
        with st.expander("GÃ¶lge BastÄ±rma (Saha AyarÄ±)", expanded=False):
            alpha_shad = st.slider("GÃ¶lge BastÄ±rma GÃ¼cÃ¼", 0.0, 1.0, 0.65, 0.05, help="Koyu + dÃ¼ÅŸÃ¼k kenarlÄ± bÃ¶lgeleri bastÄ±rma")
            beta_illum = st.slider("AydÄ±nlatma-Kenar AzaltÄ±mÄ±", 0.0, 1.0, 0.25, 0.05, help="GÃ¶rÃ¼ntÃ¼ kenarÄ± yÃ¼ksek ama derinlik kenarÄ± dÃ¼ÅŸÃ¼kse etkisini azaltÄ±r")
            shadow_cut = st.slider("GÃ¶lge Eleme EÅŸiÄŸi", 0.0, 1.0, 0.45, 0.05, help="Saf gÃ¶lge bÃ¶lgeleri eleme iÃ§in alt sÄ±nÄ±r")
            img_edge_min = st.slider("Min GÃ¶rÃ¼ntÃ¼ KenarÄ±", 0.0, 0.5, 0.10, 0.01)
            depth_edge_min = st.slider("Min Derinlik KenarÄ±", 0.0, 0.5, 0.08, 0.01)
            spec_gamma = st.slider("SpekÃ¼ler BastÄ±rma GÃ¼cÃ¼", 0.0, 1.0, 0.35, 0.05, help="YÃ¼ksek parlaklÄ±k + dÃ¼ÅŸÃ¼k satÃ¼rasyon bÃ¶lgeleri bastÄ±rma")
            spec_cut = st.slider("SpekÃ¼ler Eleme EÅŸiÄŸi", 0.0, 1.0, 0.50, 0.05)
            spec_lowvar_gamma = st.slider("DÃ¼ÅŸÃ¼k Varyans AzaltÄ±mÄ±", 0.0, 1.0, 0.35, 0.05, help="DÃ¼ÅŸÃ¼k doku (dÃ¼ÅŸÃ¼k varyans) spekÃ¼ler noktalara ek azaltÄ±m uygular")
            spec_var_thresh = st.slider("DÃ¼ÅŸÃ¼k Varyans EÅŸiÄŸi", 0.0005, 0.02, 0.005, 0.0005)

        with st.expander("Odak GÃ¶rselleri", expanded=False):
            focus_h = st.slider("Odak Karo YÃ¼ksekliÄŸi", 160, 480, 300, 10)
            focus_overlay = st.checkbox("IsÄ± + Orijinal karÄ±ÅŸÄ±mÄ±nÄ± gÃ¶ster (overlay)", value=True)
            focus_sharpen = st.checkbox("Odak KeskinleÅŸtirme (unsharp)", value=True)
            focus_hide_empty_depth = st.checkbox("Derinlik karosu yoksa gizle", value=True)
            focus_interp = st.selectbox("Yeniden Ã¶rnekleme", ["INTER_LANCZOS4", "INTER_CUBIC", "INTER_AREA"], index=0,
                help="BÃ¼yÃ¼tmede LANCZOS4/CUBIC daha okunur sonuÃ§ verir; kÃ¼Ã§Ã¼ltmede AREA tercih edilir")
            st.caption("HÄ±z iÃ§in analizden hemen sonra odak karolarÄ± Ã¶nceden Ã¼retilir.")

    # Curiosity aÄŸÄ±rlÄ±klarÄ± yÃ¶netimi (bozmadan opsiyonel)
    with st.sidebar.expander("ðŸ§­ Curiosity AÄŸÄ±rlÄ±klarÄ± (Opsiyonel)", expanded=False):
        use_loaded = st.checkbox("Dosyadan yÃ¼klenen aÄŸÄ±rlÄ±klarÄ± kullan", value=False)
        weights_path = st.text_input("AÄŸÄ±rlÄ±k dosyasÄ± (JSON)", value="results/curiosity_weights.json")
        col_w1, col_w2 = st.columns(2)
        with col_w1:
            if st.button("YÃ¼kle"):
                try:
                    with open(weights_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    models['curiosity_scorer'] = CuriosityScorer(CuriosityWeights(**data))
                    st.success("AÄŸÄ±rlÄ±klar yÃ¼klendi")
                except Exception as e:
                    st.error(f"YÃ¼kleme hatasÄ±: {e}")
        with col_w2:
            if st.button("VarsayÄ±lanlara dÃ¶n"):
                models['curiosity_scorer'] = CuriosityScorer(CuriosityWeights())
                st.info("VarsayÄ±lan aÄŸÄ±rlÄ±klar aktif")
        # GÃ¶rÃ¼ntÃ¼leme
        try:
            w = models['curiosity_scorer'].weights
            st.caption(f"Aktif: known={w.w_known:.3f}, anomaly={w.w_anomaly:.3f}, combined={w.w_combined:.3f}, dvar={w.w_depth_variance:.3f}, rough={w.w_roughness:.3f}")
        except Exception:
            pass
        globals()['use_loaded_weights'] = bool(use_loaded)
    
    # Ana iÃ§erik
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ðŸ“¸ GÃ¶rÃ¼ntÃ¼ Analizi", "ðŸ” Derinlik Analizi", "ðŸ“Š Sistem Durumu", "ðŸŽ¯ Demo Veriler", "â„¹ï¸ HakkÄ±nda"])
    
    with tab1:
        st.header("ðŸ“¸ Mars GÃ¶rÃ¼ntÃ¼sÃ¼ Hibrit Analizi")
        
        # Dosya yÃ¼kleme
        uploaded_file = st.file_uploader(
            "Mars gÃ¶rÃ¼ntÃ¼sÃ¼ yÃ¼kleyin (JPG, PNG)",
            type=['jpg', 'jpeg', 'png']
        )
        
        if uploaded_file is not None:
            # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
            image = Image.open(uploaded_file).convert('RGB')

            # Otomatik gÃ¶rÃ¼ntÃ¼ iyileÅŸtirme seÃ§enekleri
            st.subheader("ðŸ§¹ Otomatik GÃ¶rÃ¼ntÃ¼ Ä°yileÅŸtirme")
            enh_cols = st.columns(5)
            with enh_cols[0]:
                opt_upscale = st.checkbox("Upscale", value=True, help="DÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ gÃ¶rselleri akÄ±llÄ± bÃ¼yÃ¼tme")
            with enh_cols[1]:
                opt_denoise = st.checkbox("Denoise", value=True, help="YÃ¼ksek gÃ¼rÃ¼ltÃ¼lÃ¼ gÃ¶rÃ¼ntÃ¼lerde renkli gÃ¼rÃ¼ltÃ¼ giderme")
            with enh_cols[2]:
                opt_clahe = st.checkbox("Kontrast (CLAHE)", value=True)
            with enh_cols[3]:
                opt_gamma = st.checkbox("Pozlama (Gamma)", value=True)
            with enh_cols[4]:
                opt_sharp = st.checkbox("KeskinleÅŸtirme", value=True)

            # Ä°yileÅŸtirme uygula butonu
            if st.button("âœ¨ GÃ¶rÃ¼ntÃ¼yÃ¼ Otomatik Ä°yileÅŸtir"):
                cfg = dict(
                    enable_upscale=opt_upscale,
                    enable_denoise=opt_denoise,
                    enable_clahe=opt_clahe,
                    enable_gamma=opt_gamma,
                    enable_sharpen=opt_sharp,
                    target_long_side=1024,
                    denoise_h=5,
                    clahe_clip=2.0,
                    target_mean=128.0,
                    sharpen_strength=0.6,
                    sharpen_radius=2,
                )
                enhanced, before_m, after_m, steps = enhance_image_auto(image, cfg)
                st.success(f"Uygulanan adÄ±mlar: {', '.join(steps)}")
                c1, c2 = st.columns(2)
                with c1:
                    st.image(image, caption="Ã–nce", use_container_width=True)
                    st.json({"Ã–nce": before_m})
                with c2:
                    st.image(enhanced, caption="Sonra", use_container_width=True)
                    st.json({"Sonra": after_m})
                # Analizde iyileÅŸtirilmiÅŸ gÃ¶rÃ¼ntÃ¼yÃ¼ kullan
                image = enhanced
                st.session_state["enhanced_image_for_analysis"] = image
            
            # Ä°ki sÃ¼tunlu layout
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ðŸ“· Orijinal GÃ¶rÃ¼ntÃ¼")
                st.image(image, caption="YÃ¼klenen Mars gÃ¶rÃ¼ntÃ¼sÃ¼", use_container_width=True)
            
            # Analiz butonu
            clicked = st.button("ðŸ” Hibrit Analiz Et", type="primary")
            if clicked:
                with st.spinner("Hibrit analiz yapÄ±lÄ±yor (Anomali + Derinlik + Dinamik DeÄŸer)..."):
                    # KapsamlÄ± analiz
                    # Varsa iyileÅŸtirilmiÅŸ gÃ¶rÃ¼ntÃ¼yÃ¼ kullan
                    image_to_use = st.session_state.get("enhanced_image_for_analysis", image)
                    # GeliÅŸmiÅŸ tespit ayarlarÄ±nÄ± global deÄŸiÅŸken olarak geÃ§ir
                    globals().update({
                        'unified_threshold': unified_threshold,
                        'hyst_high': hyst_high,
                        'hyst_low': hyst_low,
                        'nms_iou': nms_iou,
                        'top_k': top_k,
                        'w_recon': w_recon,
                        'w_depth': w_depth,
                        'w_texture': w_texture,
                        'edge_reinf': edge_reinf,
                        'alpha_shad': alpha_shad,
                        'beta_illum': beta_illum,
                        'shadow_cut': shadow_cut,
                        'img_edge_min': img_edge_min,
                        'depth_edge_min': depth_edge_min,
                        'spec_gamma': spec_gamma,
                        'spec_cut': spec_cut,
                        'spec_lowvar_gamma': spec_lowvar_gamma,
                        'spec_var_thresh': spec_var_thresh,
                        'w_padim': w_padim,
                        'w_patchcore': w_patchcore,
                         'focus_h': focus_h,
                         'focus_overlay': focus_overlay,
                         'focus_sharpen': focus_sharpen,
                         'focus_hide_empty_depth': focus_hide_empty_depth,
                         'focus_interp': focus_interp,
                    })
                    results = analyze_mars_image(models, image_to_use)
                    # SonuÃ§larÄ± yeniden Ã§alÄ±ÅŸtÄ±rmalarda koru
                    st.session_state["results"] = results
                    
                    if results['anomaly_score'] is not None:
                        # SonuÃ§larÄ± gÃ¶ster
                        with col2:
                            st.subheader("ðŸ”„ Yeniden OluÅŸturulan GÃ¶rÃ¼ntÃ¼")
                            st.image(
                                results['reconstructed'],
                                caption=f"Anomali Skoru: {results['anomaly_score']:.6f}",
                                use_container_width=True,
                            )
                        
                        # SonuÃ§ analizi
                        st.subheader("ðŸ“Š Hibrit Analiz SonuÃ§larÄ±")
                        
                        # Metrikler
                        col1, col2, col3, col4, col5 = st.columns(5)
                        
                        with col1:
                            st.metric("Anomali Skoru (MSE)", f"{results['anomaly_score']:.6f}")
                        
                        with col2:
                            # BirleÅŸik anomali skoru (derinlik + rekonstrÃ¼ksiyon)
                            if results.get('combined_anomaly_score') is not None:
                                mse_norm = float(np.clip(results['anomaly_score'] / max(anomaly_threshold, 1e-6), 0.0, 1.0))
                                comb = float(results['combined_anomaly_score'])
                                unified_anomaly = 0.5 * mse_norm + 0.5 * comb
                                st.metric("BirleÅŸik Anomali", f"{unified_anomaly:.3f}")
                                is_anomaly = unified_anomaly > unified_threshold
                            else:
                                is_anomaly = results['anomaly_score'] > anomaly_threshold
                                st.metric("BirleÅŸik Anomali", "N/A")
                            st.metric("Anomali Durumu", "ðŸš¨ Anormal" if is_anomaly else "âœ… Normal")
                        
                        with col3:
                            st.metric("Bilinen DeÄŸer", f"{results['known_value_score']:.3f}")
                        
                        with col4:
                            # Ä°lginÃ§lik puanÄ± (modÃ¼ler skorlayÄ±cÄ±dan)
                            curiosity_score = results.get('curiosity_score')
                            if curiosity_score is None:
                                curiosity_score = alpha * results['known_value_score'] + beta * results['anomaly_score']
                            st.metric("Ä°lginÃ§lik PuanÄ±", f"{curiosity_score:.6f}")
                        
                        with col5:
                            if 'predicted_class' in results:
                                class_names = {0: "DeÄŸersiz", 1: "DÃ¼ÅŸÃ¼k", 2: "Orta", 3: "Orta-YÃ¼ksek", 4: "YÃ¼ksek"}
                                predicted_name = class_names.get(results['predicted_class'], "Bilinmiyor")
                                st.metric("Tahmin Edilen SÄ±nÄ±f", predicted_name)
                        
                        # Fark gÃ¶rÃ¼ntÃ¼sÃ¼ + birleÅŸik anomali haritasÄ±
                        st.subheader("ðŸ” Fark ve BirleÅŸik Anomali HaritasÄ±")
                        diff = np.abs(results['original'] - results['reconstructed'])

                        if results.get('combined_anomaly_map') is not None:
                            comb_map = results['combined_anomaly_map']
                            # Orijinale Ä±sÄ± haritasÄ± bindirme (boyutlarÄ± eÅŸitle)
                            H, W = comb_map.shape[:2]
                            base = (results['original'] * 255).astype(np.uint8)
                            if base.shape[:2] != (H, W):
                                base = cv2.resize(base, (W, H), interpolation=cv2.INTER_LINEAR)
                            if base.ndim == 2:
                                base = cv2.cvtColor(base, cv2.COLOR_GRAY2RGB)
                            heat = (plt.cm.inferno(comb_map)[..., :3] * 255).astype(np.uint8)
                            overlay = cv2.addWeighted(base, 0.6, heat, 0.4, 0)

                            fig, axes = plt.subplots(1, 4, figsize=(20, 5))
                            _safe_imshow(axes[0], results['original'])
                            axes[0].set_title("Original")
                            axes[0].axis('off')
                            _safe_imshow(axes[1], results['reconstructed'])
                            axes[1].set_title("Reconstructed")
                            axes[1].axis('off')
                            _safe_imshow(axes[2], diff, cmap='hot')
                            axes[2].set_title("Difference")
                            axes[2].axis('off')
                            _safe_imshow(axes[3], overlay)
                            axes[3].set_title("Combined Anomaly (overlay)")
                            axes[3].axis('off')
                            st.pyplot(fig)

                            # Tespit kutularÄ±nÄ± gÃ¶ster (tespit olmasa da overlay gÃ¶ster)
                            # Combined anomaly overlay'i hafifÃ§e bÃ¼yÃ¼t, sonra etiketleri Ã§iz
                            detections = results.get('detections') or []
                            # SaÄŸ panelde seÃ§im durum anahtarÄ±nÄ± hazÄ±rla
                            select_key = "diag_selected_idx"
                            if select_key not in st.session_state:
                                st.session_state[select_key] = 0
                            col_vis, col_diag = st.columns([3, 2], gap="large")
                            with col_diag:
                                st.subheader("ðŸ”Ž Tespit TanÄ±lama Paneli")
                                with st.expander("â“ Metrik AÃ§Ä±klamalarÄ±", expanded=False):
                                    st.markdown(
                                        "- **sc**: BirleÅŸik anomali skoru\n"
                                        "- **e**: Kenar yoÄŸunluÄŸu gÃ¶stergesi\n"
                                        "- **s**: GÃ¶lge/karanlÄ±k etkisi (azaltÄ±m)\n"
                                        "- **sp**: Parlama (spekÃ¼ler) etkisi (azaltÄ±m)\n"
                                        "- **lv**: DÃ¼ÅŸÃ¼k doku/varians etkisi (azaltÄ±m)"
                                    )
                                # HÄ±zlÄ± seÃ§im widget'Ä±nÄ± Ã–NCE oluÅŸtur ki bu turda seÃ§imi kullanabilelim
                                try:
                                    table_rows = []
                                    for i, det in enumerate(detections, start=1):
                                        table_rows.append({
                                            "#": i,
                                            "sc": round(float(det.get('score', 0.0)), 3),
                                            "e": round(float(det.get('edge_mean', 0.0)), 3),
                                            "s": round(float(det.get('shadow_pen', 0.0)), 3),
                                            "sp": round(float(det.get('spec_pen', 0.0)), 3),
                                            "lv": round(float(det.get('lowvar_pen', 0.0)), 3),
                                        })
                                    if len(table_rows) > 0:
                                        st.table(table_rows)
                                        _ = st.radio(
                                            "HÄ±zlÄ± SeÃ§im",
                                            options=[0] + [r["#"] for r in table_rows],
                                            index=([0] + [r["#"] for r in table_rows]).index(st.session_state.get(select_key, 0) if st.session_state.get(select_key, 0) in ([0] + [r["#"] for r in table_rows]) else 0),
                                            format_func=lambda i: ("TÃ¼mÃ¼" if i == 0 else f"#{i}"),
                                            horizontal=True,
                                            key=select_key,
                                        )
                                except Exception:
                                    pass
                            try:
                                selected_idx = int(st.session_state.get(select_key, 0))
                            except Exception:
                                selected_idx = 0
                            oh0, ow0 = overlay.shape[0], overlay.shape[1]
                            scale_up = 2.5  # istenen bÃ¼yÃ¼tme (1.6x)
                            disp = cv2.resize(
                                overlay,
                                (int(round(ow0 * scale_up)), int(round(oh0 * scale_up))),
                                interpolation=cv2.INTER_CUBIC,
                            )
                            disp_base = disp.copy()
                            # Odak modu: seÃ§ili anomali varsa arka planÄ± yumuÅŸak maske ile karart ve seÃ§ilen bÃ¶lgeyi Ã¶n plana Ã§Ä±kar
                            if selected_idx > 0 and selected_idx <= len(detections):
                                sel = detections[selected_idx - 1]
                                sx, sy, sw, sh = sel['x'], sel['y'], sel['w'], sel['h']
                                sxs, sys = int(round(sx * scale_up)), int(round(sy * scale_up))
                                sws, shs = int(round(sw * scale_up)), int(round(sh * scale_up))
                                dimmed = (disp * 0.20).astype(np.uint8)
                                mask = np.zeros((disp.shape[0], disp.shape[1]), dtype=np.float32)
                                y1 = max(0, sys)
                                y2 = min(disp.shape[0], sys + shs)
                                x1 = max(0, sxs)
                                x2 = min(disp.shape[1], sxs + sws)
                                if y2 > y1 and x2 > x1:
                                    mask[y1:y2, x1:x2] = 1.0
                                    mask = cv2.GaussianBlur(mask, (61, 61), 0)
                                    mask = np.clip(mask, 0.0, 1.0)[..., None]
                                    disp = (disp_base.astype(np.float32) * mask + dimmed.astype(np.float32) * (1.0 - mask)).astype(np.uint8)

                            diag_lines = []
                            for i, det in enumerate(detections):
                                x, y, w, h = det['x'], det['y'], det['w'], det['h']
                                xs, ys = int(round(x * scale_up)), int(round(y * scale_up))
                                ws, hs = int(round(w * scale_up)), int(round(h * scale_up))
                                idx_num = i + 1
                                is_selected = (selected_idx == idx_num)
                                box_color = (255, 0, 0) if is_selected else (0, 255, 0)
                                box_thickness = 2 if is_selected else 2
                                if det.get('poly'):
                                    pts = np.array(det['poly'], dtype=np.float32).reshape((-1, 2))
                                    pts = (pts * scale_up).astype(np.int32).reshape((-1, 1, 2))
                                    cv2.polylines(disp, [pts], isClosed=True, color=box_color, thickness=box_thickness)
                                else:
                                    cv2.rectangle(disp, (xs, ys), (xs + ws, ys + hs), box_color, box_thickness)
                                # Okunur etiket (opak zemin): sadece numara
                                label = f"#{idx_num}"
                                # Etiketleri biraz daha kÃ¼Ã§Ã¼lt
                                font_scale = 0.26 * scale_up
                                text_thickness = 1
                                (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_thickness)
                                bx1, by1 = xs, max(0, ys - th - 6)
                                bx2, by2 = xs + tw + 6, by1 + th + 4
                                cv2.rectangle(disp, (bx1, by1), (bx2, by2), box_color, -1)
                                cv2.putText(disp, label, (xs + 3, by2 - 4), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), text_thickness, cv2.LINE_AA)
                                # Mini-diagnostic metni bir listede topla (saÄŸ panelde gÃ¶sterilecek)
                                diag = f"#{idx_num} sc:{det.get('score',0):.2f} e:{det.get('edge_mean',0):.2f} s:{det.get('shadow_pen',0):.2f} sp:{det.get('spec_pen',0):.2f} lv:{det.get('lowvar_pen',0):.2f}"
                                diag_lines.append(diag)

                            # Not: diag_lines ayrÄ± panelde gÃ¶sterilecektir (gÃ¶rsele eklenmez)
                            # OdaklÄ± gÃ¶rÃ¼nÃ¼m: seÃ§ili anomali varsa ana gÃ¶rseli de merkezleyip yakÄ±nlaÅŸtÄ±r
                            disp_to_show = disp
                            if selected_idx > 0 and selected_idx <= len(detections):
                                cx = sxs + sws // 2
                                cy = sys + shs // 2
                                # Hedef kÄ±rpma boyutu: seÃ§ili kutudan daha geniÅŸ bir pencere
                                crop_w = int(min(disp.shape[1], max(int(sws * 2.5), 520)))
                                crop_h = int(min(disp.shape[0], max(int(shs * 2.5), 520)))
                                x1 = max(0, min(disp.shape[1] - crop_w, cx - crop_w // 2))
                                y1 = max(0, min(disp.shape[0] - crop_h, cy - crop_h // 2))
                                x2 = x1 + crop_w
                                y2 = y1 + crop_h
                                if (y2 - y1) > 10 and (x2 - x1) > 10:
                                    disp_to_show = disp[y1:y2, x1:x2]
                            # GÃ¶sterimi sabit hedef geniÅŸliÄŸe gÃ¶re yeniden boyutlandÄ±r (biraz daha bÃ¼yÃ¼k hedef)
                            oh, ow = disp_to_show.shape[0], disp_to_show.shape[1]
                            pref_w = 860
                            scale = min(0.95, max(0.60, float(pref_w) / max(1.0, float(ow))))
                            target_w = max(1, int(round(ow * scale)))
                            target_h = max(1, int(round(oh * scale)))
                            disp_small = cv2.resize(disp_to_show, (target_w, target_h), interpolation=cv2.INTER_AREA)
                            caption = "BirleÅŸik Anomali Tespitleri" + (" â€” tespit bulunamadÄ±" if len(detections) == 0 else "")
                            # GÃ¶rsel ve paneli yukarÄ±da oluÅŸturduÄŸumuz kolonlarda gÃ¶ster
                            with col_vis:
                                st.markdown('<div id="anomaly_anchor"></div>', unsafe_allow_html=True)
                                st.image(
                                    disp_small,
                                    caption=f"{caption} (kÃ¼Ã§Ã¼k cisimler dahil edilir)",
                                    use_container_width=False,
                                )
                            with col_diag:
                                if diag_lines:
                                    st.code("\n".join(diag_lines), language="text")
                                else:
                                    st.info("Tespit bulunamadÄ± veya tanÄ±lama verisi yok.")
                                # SeÃ§ili anomali iÃ§in yakÄ±nlaÅŸtÄ±rÄ±lmÄ±ÅŸ odak gÃ¶rÃ¼ntÃ¼sÃ¼
                                try:
                                    selected_idx_view = int(st.session_state.get(select_key, 0))
                                except Exception:
                                    selected_idx_view = 0
                                if selected_idx_view > 0 and selected_idx_view <= len(detections):
                                    tiles = results.get('focus_tiles') or []
                                    tile = tiles[selected_idx_view - 1] if (selected_idx_view - 1) < len(tiles) else None
                                    if tile is not None:
                                        st.image(tile, caption=f"Odak: #{selected_idx_view}")
                                # SeÃ§im deÄŸiÅŸtiÄŸinde otomatik kaydÄ±rma
                                _prev = st.session_state.get("_prev_selected_idx", -1)
                                if _prev != selected_idx:
                                    st.session_state["_prev_selected_idx"] = selected_idx
                                    st.markdown("""
                                        <script>
                                        const el = document.getElementById('anomaly_anchor');
                                        if (el) { el.scrollIntoView({behavior: 'smooth', block: 'center'}); }
                                        </script>
                                    """, unsafe_allow_html=True)
                        else:
                            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
                            _safe_imshow(axes[0], results['original'])
                            axes[0].set_title("Original")
                            axes[0].axis('off')
                            _safe_imshow(axes[1], results['reconstructed'])
                            axes[1].set_title("Reconstructed")
                            axes[1].axis('off')
                            _safe_imshow(axes[2], diff, cmap='hot')
                            axes[2].set_title("Difference (Anomaly)")
                            axes[2].axis('off')
                            st.pyplot(fig)

            # EÄŸer sonuÃ§ daha Ã¶nce Ã¼retildiyse (Ã¶r. seÃ§im deÄŸiÅŸince rerun), tekrar gÃ¶ster
            persisted = st.session_state.get("results")
            if persisted and not clicked:
                results = persisted
                diff = np.abs(results['original'] - results['reconstructed'])
                if results.get('combined_anomaly_map') is not None:
                    comb_map = results['combined_anomaly_map']
                    H, W = comb_map.shape[:2]
                    base = (results['original'] * 255).astype(np.uint8)
                    if base.shape[:2] != (H, W):
                        base = cv2.resize(base, (W, H), interpolation=cv2.INTER_LINEAR)
                    if base.ndim == 2:
                        base = cv2.cvtColor(base, cv2.COLOR_GRAY2RGB)
                    heat = (plt.cm.inferno(comb_map)[..., :3] * 255).astype(np.uint8)
                    overlay = cv2.addWeighted(base, 0.6, heat, 0.4, 0)

                    fig, axes = plt.subplots(1, 4, figsize=(20, 5))
                    _safe_imshow(axes[0], results['original'])
                    axes[0].set_title("Original")
                    axes[0].axis('off')
                    _safe_imshow(axes[1], results['reconstructed'])
                    axes[1].set_title("Reconstructed")
                    axes[1].axis('off')
                    _safe_imshow(axes[2], diff, cmap='hot')
                    axes[2].set_title("Difference")
                    axes[2].axis('off')
                    _safe_imshow(axes[3], overlay)
                    axes[3].set_title("Combined Anomaly (overlay)")
                    axes[3].axis('off')
                    st.pyplot(fig)

                    detections = results.get('detections') or []
                    select_key = "diag_selected_idx"
                    if select_key not in st.session_state:
                        st.session_state[select_key] = 0
                    col_vis, col_diag = st.columns([3, 2], gap="large")
                    with col_diag:
                        st.subheader("ðŸ”Ž Tespit TanÄ±lama Paneli")
                        with st.expander("â“ Metrik AÃ§Ä±klamalarÄ±", expanded=False):
                            st.markdown(
                                "- **sc**: BirleÅŸik anomali skoru\n"
                                "- **e**: Kenar yoÄŸunluÄŸu gÃ¶stergesi\n"
                                "- **s**: GÃ¶lge/karanlÄ±k etkisi (azaltÄ±m)\n"
                                "- **sp**: Parlama (spekÃ¼ler) etkisi (azaltÄ±m)\n"
                                "- **lv**: DÃ¼ÅŸÃ¼k doku/varians etkisi (azaltÄ±m)"
                            )
                        # HÄ±zlÄ± seÃ§im bileÅŸeni: aynÄ± turda seÃ§imi yakalamak iÃ§in Ã–NCE oluÅŸtur
                        if len(detections) > 0:
                            try:
                                table_rows = []
                                for i, det in enumerate(detections, start=1):
                                    table_rows.append({
                                        "#": i,
                                        "sc": round(float(det.get('score', 0.0)), 3),
                                        "e": round(float(det.get('edge_mean', 0.0)), 3),
                                        "s": round(float(det.get('shadow_pen', 0.0)), 3),
                                        "sp": round(float(det.get('spec_pen', 0.0)), 3),
                                        "lv": round(float(det.get('lowvar_pen', 0.0)), 3),
                                    })
                                st.table(table_rows)
                                _ = st.radio(
                                    "HÄ±zlÄ± SeÃ§im",
                                    options=[0] + [r["#"] for r in table_rows],
                                    index=([0] + [r["#"] for r in table_rows]).index(st.session_state.get(select_key, 0) if st.session_state.get(select_key, 0) in ([0] + [r["#"] for r in table_rows]) else 0),
                                    format_func=lambda i: ("TÃ¼mÃ¼" if i == 0 else f"#{i}"),
                                    horizontal=True,
                                    key=select_key,
                                )
                            except Exception:
                                pass

                    oh0, ow0 = overlay.shape[0], overlay.shape[1]
                    scale_up = 1.60
                    disp = cv2.resize(overlay, (int(round(ow0 * scale_up)), int(round(oh0 * scale_up))), interpolation=cv2.INTER_CUBIC)
                    disp_base = disp.copy()
                    try:
                        selected_idx = int(st.session_state.get(select_key, 0))
                    except Exception:
                        selected_idx = 0
                    if selected_idx > 0 and selected_idx <= len(detections):
                        sel = detections[selected_idx - 1]
                        sx, sy, sw, sh = sel['x'], sel['y'], sel['w'], sel['h']
                        sxs, sys = int(round(sx * scale_up)), int(round(sy * scale_up))
                        sws, shs = int(round(sw * scale_up)), int(round(sh * scale_up))
                        dimmed = (disp * 0.25).astype(np.uint8)
                        disp = dimmed
                        y1 = max(0, sys); y2 = min(disp.shape[0], sys + shs)
                        x1 = max(0, sxs); x2 = min(disp.shape[1], sxs + sws)
                        if y2 > y1 and x2 > x1:
                            disp[y1:y2, x1:x2] = disp_base[y1:y2, x1:x2]

                    diag_lines = []
                    for i, det in enumerate(detections):
                        x, y, w, h = det['x'], det['y'], det['w'], det['h']
                        xs, ys = int(round(x * scale_up)), int(round(y * scale_up))
                        ws, hs = int(round(w * scale_up)), int(round(h * scale_up))
                        idx_num = i + 1
                        is_selected = (selected_idx == idx_num)
                        box_color = (255, 0, 0) if is_selected else (0, 255, 0)
                        box_thickness = 2 if is_selected else 2
                        if det.get('poly'):
                            pts = np.array(det['poly'], dtype=np.float32).reshape((-1, 2))
                            pts = (pts * scale_up).astype(np.int32).reshape((-1, 1, 2))
                            cv2.polylines(disp, [pts], isClosed=True, color=box_color, thickness=box_thickness)
                        else:
                            cv2.rectangle(disp, (xs, ys), (xs + ws, ys + hs), box_color, box_thickness)
                        label = f"#{idx_num}"
                        font_scale = 0.26 * scale_up
                        text_thickness = 1
                        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_thickness)
                        bx1, by1 = xs, max(0, ys - th - 6)
                        bx2, by2 = xs + tw + 6, by1 + th + 4
                        cv2.rectangle(disp, (bx1, by1), (bx2, by2), box_color, -1)
                        cv2.putText(disp, label, (xs + 3, by2 - 4), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), text_thickness, cv2.LINE_AA)
                        diag = f"#{idx_num} sc:{det.get('score',0):.2f} e:{det.get('edge_mean',0):.2f} s:{det.get('shadow_pen',0):.2f} sp:{det.get('spec_pen',0):.2f} lv:{det.get('lowvar_pen',0):.2f}"
                        diag_lines.append(diag)

                    disp_to_show = disp
                    if selected_idx > 0 and selected_idx <= len(detections):
                        cx = sxs + sws // 2; cy = sys + shs // 2
                        crop_w = int(min(disp.shape[1], max(int(sws * 2.5), 520)))
                        crop_h = int(min(disp.shape[0], max(int(shs * 2.5), 520)))
                        x1 = max(0, min(disp.shape[1] - crop_w, cx - crop_w // 2))
                        y1 = max(0, min(disp.shape[0] - crop_h, cy - crop_h // 2))
                        x2 = x1 + crop_w; y2 = y1 + crop_h
                        if (y2 - y1) > 10 and (x2 - x1) > 10:
                            disp_to_show = disp[y1:y2, x1:x2]

                    oh, ow = disp_to_show.shape[0], disp_to_show.shape[1]
                    pref_w = 860
                    scale = min(0.95, max(0.60, float(pref_w) / max(1.0, float(ow))))
                    target_w = max(1, int(round(ow * scale)))
                    target_h = max(1, int(round(oh * scale)))
                    disp_small = cv2.resize(disp_to_show, (target_w, target_h), interpolation=cv2.INTER_AREA)
                    caption = "BirleÅŸik Anomali Tespitleri" + (" â€” tespit bulunamadÄ±" if len(detections) == 0 else "")
                    with col_vis:
                        st.image(disp_small, caption=f"{caption} (kÃ¼Ã§Ã¼k cisimler dahil edilir)", use_container_width=False)
                    with col_diag:
                        if diag_lines:
                            st.code("\n".join(diag_lines), language="text")
                        else:
                            st.info("Tespit bulunamadÄ± veya tanÄ±lama verisi yok.")
                        try:
                            selected_idx_view = int(st.session_state.get(select_key, 0))
                        except Exception:
                            selected_idx_view = 0
                        if selected_idx_view > 0 and selected_idx_view <= len(detections):
                            tiles = results.get('focus_tiles') or []
                            tile = tiles[selected_idx_view - 1] if (selected_idx_view - 1) < len(tiles) else None
                            if tile is not None:
                                st.image(tile, caption=f"Odak: #{selected_idx_view}")
                        
                        # is_anomaly'yi (persisted sonuÃ§lar iÃ§in) yeniden hesapla
                        try:
                            unified_anomaly = results.get('combined_anomaly_score')
                        except Exception:
                            unified_anomaly = None
                        if unified_anomaly is None and results.get('combined_anomaly_map') is not None:
                            try:
                                unified_anomaly = float(np.mean(results['combined_anomaly_map']))
                            except Exception:
                                unified_anomaly = None
                        if unified_anomaly is not None:
                            is_anomaly = bool(unified_anomaly > unified_threshold)
                        else:
                            try:
                                is_anomaly = bool(results.get('anomaly_score', 0.0) > anomaly_threshold)
                            except Exception:
                                is_anomaly = False

                        # Ã–neriler
                        st.subheader("ðŸ’¡ Hibrit Ã–neriler")
                        
                        if is_anomaly and results['known_value_score'] > 0.6:
                            st.success("ðŸŽ¯ **YÃœKSEK Ã–NCELÄ°K**: Bu hedef hem anormal hem de yÃ¼ksek bilimsel deÄŸere sahip!")
                        elif is_anomaly:
                            st.warning("ðŸ” **ORTA Ã–NCELÄ°K**: Bu hedef anormal ama bilimsel deÄŸeri orta seviyede.")
                        elif results['known_value_score'] > 0.7:
                            st.info("ðŸ“‹ **DÃœÅžÃœK Ã–NCELÄ°K**: Bu hedef normal ama bilinen deÄŸerli hedeflere benziyor.")
                        else:
                            st.info("ðŸ“‹ **DÃœÅžÃœK Ã–NCELÄ°K**: Bu hedef normal Mars yÃ¼zeyi gÃ¶rÃ¼nÃ¼yor.")
    
    with tab2:
        st.header("ðŸ” Derinlik Analizi")
        
        if uploaded_file is not None and 'depth_estimator' in models:
            depth_model_info = models['depth_model_info']
            st.subheader(f"ðŸŒŠ Derinlik HaritasÄ± ({depth_model_info['model_type']}) - {'YÃ¼ksek DoÄŸruluk' if depth_model_info['is_real_dpt'] else 'Basit Model'}")
            
            # KullanÄ±cÄ± seÃ§enekleri: Ã§Ã¶zÃ¼nÃ¼rlÃ¼k ve iyileÅŸtirme
            col_opts1, col_opts2, col_opts3 = st.columns(3)
            with col_opts1:
                target_resolution = st.selectbox(
                    "Ã‡Ã¶zÃ¼nÃ¼rlÃ¼k",
                    options=[512, 768, 1024],
                    index=2,
                    help="GiriÅŸ gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼n analizde kullanÄ±lacak Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼"
                )
            with col_opts2:
                apply_enhancement = st.checkbox(
                    "GeliÅŸtirme Uygula (kontrast + keskinleÅŸtirme)",
                    value=True
                )
            with col_opts3:
                show_raw_compare = st.checkbox(
                    "Ham Ã§Ä±ktÄ±yla karÅŸÄ±laÅŸtÄ±r",
                    value=False,
                    help="GeliÅŸtirme kapalÄ± (ham) ve aÃ§Ä±k Ã§Ä±ktÄ±larÄ± yan yana gÃ¶ster"
                )

            # Derinlik analizi (yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼k)
            image = Image.open(uploaded_file).convert('RGB')
            # Varsa gÃ¶rÃ¼ntÃ¼ iyileÅŸtirme sonrasÄ± sÃ¼rÃ¼mÃ¼ kullan
            image = st.session_state.get("enhanced_image_for_analysis", image)
            # SeÃ§ilen Ã§Ã¶zÃ¼nÃ¼rlÃ¼kte iÅŸle
            image_array = np.array(image.resize((target_resolution, target_resolution), Image.LANCZOS), dtype=np.float32) / 255.0
            
            try:
                # Ä°yileÅŸtirme aÃ§Ä±k/kapalÄ± seÃ§enekleri
                t0 = time.perf_counter()
                depth_map, metadata = models['depth_estimator'].estimate_depth(
                    image_array,
                    apply_enhancement=apply_enhancement,
                    guide_image=np.array(image),
                    high_detail=True,
                    tta_flips=True,
                    use_fgs=True,
                    use_wmf=True,
                )
                t1 = time.perf_counter()
                infer_ms = (t1 - t0) * 1000.0
                
                # Derinlik gÃ¶rselleÅŸtirmesi
                col1, col2 = st.columns(2)
                
                with col1:
                    st.image(image, caption="Orijinal GÃ¶rÃ¼ntÃ¼", use_container_width=True)
                
                with col2:
                    # GeliÅŸtirilmiÅŸ derinlik gÃ¶rselleÅŸtirmesi
                    fig, ax = plt.subplots(figsize=(10, 8))
                    
                    # Daha iyi colormap ve kontrast (turbo daha kontrastlÄ±)
                    im = ax.imshow(depth_map, cmap='turbo', interpolation='bilinear')
                    ax.set_title("Gelistirilmis Derinlik Haritasi", fontsize=14, fontweight='bold')
                    ax.axis('off')
                    
                    # GeliÅŸtirilmiÅŸ colorbar
                    cbar = plt.colorbar(im, ax=ax, shrink=0.8, aspect=20)
                    cbar.set_label('Derinlik (0=YakÄ±n, 1=Uzak)', fontsize=12)
                    cbar.ax.tick_params(labelsize=10)
                    
                    # Grid ekle
                    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)
                    
                    plt.tight_layout()
                    st.pyplot(fig)

                # Ä°steÄŸe baÄŸlÄ±: ham Ã§Ä±ktÄ± ile karÅŸÄ±laÅŸtÄ±rma
                if show_raw_compare:
                    depth_raw, _ = models['depth_estimator'].estimate_depth(
                        image_array, apply_enhancement=False, guide_image=np.array(image), high_detail=True
                    )
                    fig_cmp, (axc1, axc2) = plt.subplots(1, 2, figsize=(14, 6))
                    axc1.imshow(depth_raw, cmap='turbo', interpolation='bilinear')
                    axc1.set_title('Ham DPT Ã‡Ä±kÄ±ÅŸÄ±')
                    axc1.axis('off')
                    axc2.imshow(depth_map, cmap='turbo', interpolation='bilinear')
                    axc2.set_title('GeliÅŸtirme UygulandÄ±' if apply_enhancement else 'GeliÅŸtirme KapalÄ±')
                    axc2.axis('off')
                    plt.tight_layout()
                    st.pyplot(fig_cmp)
                    
                # Derinlik analizi bilgileri ve sÃ¼re
                st.info(f"ðŸ“Š **Derinlik Analizi ({depth_model_info['model_type']})**: {depth_map.shape[1]}x{depth_map.shape[0]} Ã§Ã¶zÃ¼nÃ¼rlÃ¼k, "
                       f"Kontrast: {depth_map.std():.3f}, Ortalama Derinlik: {depth_map.mean():.3f}, SÃ¼re: {infer_ms:.1f} ms")
                
                # Ä°nce ayar paneli
                with st.expander("ðŸ”§ Derinlik Ä°nce Ayar (GeliÅŸmiÅŸ)", expanded=False):
                    colp1, colp2, colp3 = st.columns(3)
                    with colp1:
                        gf_radius = st.slider("GuidedFilter radius", 2, 32, 8, 1,
                                              help="Guided Filter yarÄ±Ã§apÄ±. BÃ¼yÃ¼k deÄŸer: daha geniÅŸ, pÃ¼rÃ¼zsÃ¼z ancak kenar yumuÅŸamasÄ± artabilir.")
                        gf_eps = st.number_input("GuidedFilter eps", min_value=1e-6, max_value=1e-1, value=1e-2, step=1e-3, format="%f",
                                                 help="Guided Filter epsilon. DÃ¼ÅŸÃ¼k eps: daha keskin; yÃ¼ksek eps: daha yumuÅŸak.")
                        jbf_d = st.slider("JointBF d", 1, 21, 9, 1,
                                          help="Joint Bilateral filtre Ã§ekirdek Ã§apÄ±. Kenar korumalÄ± yumuÅŸatma iÃ§in pencere boyutu.")
                    with colp2:
                        jbf_sc = st.slider("JointBF sigmaColor", 1, 100, 25, 1,
                                           help="Renk/yoÄŸunluk duyarlÄ±lÄ±ÄŸÄ±. YÃ¼ksek deÄŸer: daha fazla yumuÅŸatma, kenar kaÃ§aklarÄ± artabilir.")
                        jbf_ss = st.slider("JointBF sigmaSpace", 1, 100, 25, 1,
                                           help="Uzamsal duyarlÄ±lÄ±k. YÃ¼ksek deÄŸer: daha geniÅŸ etkili alan, daha pÃ¼rÃ¼zsÃ¼z sonuÃ§.")
                        fgs_lambda = st.slider("FGS lambda", 1.0, 2000.0, 500.0, 1.0,
                                               help="Fast Global Smoother dÃ¼zgÃ¼nleÅŸtirme gÃ¼cÃ¼. BÃ¼yÃ¼k deÄŸer: daha dÃ¼z, kÃ¼Ã§Ã¼k detaylar azalabilir.")
                    with colp3:
                        fgs_sigma = st.slider("FGS sigma_color", 0.1, 5.0, 1.5, 0.1,
                                              help="FGS iÃ§in renk alanÄ± Ã¶lÃ§eÄŸi. Kenar hassasiyetini etkiler.")
                        wmf_radius = st.slider("WMF radius", 1, 31, 7, 1,
                                               help="Weighted Median Filter yarÄ±Ã§apÄ±. GÃ¼rÃ¼ltÃ¼ye karÅŸÄ± saÄŸlam, kenarlarÄ± iyi korur.")
                        wmf_sigma = st.slider("WMF sigma", 1.0, 80.0, 25.5, 0.5,
                                              help="WMF aÄŸÄ±rlÄ±klandÄ±rma gÃ¼cÃ¼. BÃ¼yÃ¼k deÄŸer: daha fazla dÃ¼zeltme/yumuÅŸatma.")
                    if st.button("Uygula (Derinlik Ä°yileÅŸtirmeyi GÃ¼ncelle)"):
                        models['depth_estimator'].set_refine_params(
                            gf_radius=gf_radius, gf_eps=float(gf_eps), jbf_d=jbf_d,
                            jbf_sigma_color=jbf_sc, jbf_sigma_space=jbf_ss,
                            fgs_lambda=float(fgs_lambda), fgs_sigma_color=float(fgs_sigma),
                            wmf_radius=wmf_radius, wmf_sigma=float(wmf_sigma),
                        )
                        st.success("Ä°nce ayar parametreleri gÃ¼ncellendi. 'Derinlik Analizi' bÃ¶lÃ¼mÃ¼nÃ¼ tekrar Ã§alÄ±ÅŸtÄ±rÄ±n.")

                # Colormap seÃ§enekleri
                st.subheader("ðŸŽ¨ Derinlik GÃ¶rselleÅŸtirme SeÃ§enekleri")
                colormap_option = st.selectbox(
                    "Colormap SeÃ§in:",
                    ["turbo", "plasma", "inferno", "magma", "viridis", "cividis"],
                    index=0,
                    help="FarklÄ± colormap'ler derinlik detaylarÄ±nÄ± farklÄ± ÅŸekilde vurgular"
                )
                
                # SeÃ§ilen colormap ile yeniden Ã§iz
                fig2, ax2 = plt.subplots(figsize=(10, 8))
                im2 = ax2.imshow(depth_map, cmap=colormap_option, interpolation='bilinear')
                ax2.set_title(f"Derinlik Haritasi ({colormap_option})", fontsize=14, fontweight='bold')
                ax2.axis('off')
                
                cbar2 = plt.colorbar(im2, ax=ax2, shrink=0.8, aspect=20)
                cbar2.set_label('Derinlik (0=YakÄ±n, 1=Uzak)', fontsize=12)
                cbar2.ax.tick_params(labelsize=10)
                
                ax2.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)
                plt.tight_layout()
                st.pyplot(fig2)
                
                # Derinlik Ã¶zelliklerini Ã§Ä±kar
                depth_features = models['depth_estimator'].extract_depth_features(depth_map)
                
                # Derinlik Ã¶zellikleri
                st.subheader("ðŸ“Š GeliÅŸtirilmiÅŸ Derinlik Ã–zellikleri")
                
                # Ã–zellikleri gÃ¶ster (daha detaylÄ±)
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("ðŸŒŠ Ortalama Derinlik", f"{depth_features.get('depth_mean', 0):.3f}")
                    st.metric("ðŸ“ Derinlik Std", f"{depth_features.get('depth_std', 0):.3f}")
                    st.metric("ðŸ“Š Derinlik VaryansÄ±", f"{depth_features.get('depth_variance', 0):.3f}")
                
                with col2:
                    st.metric("â¬‡ï¸ Min Derinlik", f"{depth_features.get('depth_min', 0):.3f}")
                    st.metric("â¬†ï¸ Max Derinlik", f"{depth_features.get('depth_max', 0):.3f}")
                    st.metric("ðŸ“ˆ Derinlik Medyan", f"{depth_features.get('depth_median', 0):.3f}")
                
                with col3:
                    st.metric("ðŸ”ï¸ YÃ¼zey KarmaÅŸÄ±klÄ±ÄŸÄ±", f"{depth_features.get('surface_complexity', 0):.3f}")
                    st.metric("ðŸŒŠ Gradient Ortalama", f"{depth_features.get('depth_gradient_mean', 0):.3f}")
                    st.metric("ðŸ“ Gradient Std", f"{depth_features.get('depth_gradient_std', 0):.3f}")
                
                with col4:
                    st.metric("ðŸ“Š Skewness", f"{depth_features.get('depth_skewness', 0):.3f}")
                    st.metric("ðŸ“ˆ Kurtosis", f"{depth_features.get('depth_kurtosis', 0):.3f}")
                    st.metric("ðŸŽ¯ P75-P25", f"{depth_features.get('depth_percentile_75', 0) - depth_features.get('depth_percentile_25', 0):.3f}")
                
                # Derinlik metadata ve ek analizler
                st.subheader("ðŸ“‹ Derinlik Metadata")
                st.json(metadata)
                
                # Derinlik histogramÄ±
                st.subheader("ðŸ“Š Derinlik DaÄŸÄ±lÄ±mÄ±")
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
                
                # Histogram
                ax1.hist(depth_map.flatten(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')
                ax1.set_title("Depth Histogram")
                ax1.set_xlabel("Depth Value")
                ax1.set_ylabel("Frequency")
                ax1.grid(True, alpha=0.3)
                
                # 3D yÃ¼zey plot (kÃ¼Ã§Ã¼k Ã¶rnek)
                try:
                    sample_size = min(50, depth_map.shape[0], depth_map.shape[1])
                    sample_depth = depth_map[::depth_map.shape[0]//sample_size, ::depth_map.shape[1]//sample_size]
                    y, x = np.mgrid[0:sample_depth.shape[0], 0:sample_depth.shape[1]]
                    
                    surf = ax2.plot_surface(x, y, sample_depth, cmap='viridis', alpha=0.8)
                    ax2.set_title("3D Depth Surface (Sample)")
                    ax2.set_xlabel("X")
                    ax2.set_ylabel("Y")
                    ax2.set_zlabel("Depth")
                except Exception as e:
                    # 3D plot baÅŸarÄ±sÄ±z olursa 2D contour plot gÃ¶ster
                    ax2.contourf(sample_depth, cmap='viridis', levels=20)
                    ax2.set_title("2D Depth Contour (Fallback)")
                    ax2.set_xlabel("X")
                    ax2.set_ylabel("Y")
                
                plt.tight_layout()
                st.pyplot(fig)
                
                # Derinlik kalitesi deÄŸerlendirmesi
                st.subheader("ðŸŽ¯ Derinlik Kalitesi DeÄŸerlendirmesi")
                
                # Kalite metrikleri
                depth_contrast = depth_map.std()
                depth_range = depth_map.max() - depth_map.min()
                depth_smoothness = 1.0 / (1.0 + depth_features.get('surface_complexity', 0))
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if depth_contrast > 0.1:
                        st.success(f"âœ… **YÃ¼ksek Kontrast**: {depth_contrast:.3f}")
                    elif depth_contrast > 0.05:
                        st.warning(f"âš ï¸ **Orta Kontrast**: {depth_contrast:.3f}")
                    else:
                        st.error(f"âŒ **DÃ¼ÅŸÃ¼k Kontrast**: {depth_contrast:.3f}")
                
                with col2:
                    if depth_range > 0.5:
                        st.success(f"âœ… **GeniÅŸ Derinlik AralÄ±ÄŸÄ±**: {depth_range:.3f}")
                    elif depth_range > 0.2:
                        st.warning(f"âš ï¸ **Orta Derinlik AralÄ±ÄŸÄ±**: {depth_range:.3f}")
                    else:
                        st.error(f"âŒ **Dar Derinlik AralÄ±ÄŸÄ±**: {depth_range:.3f}")
                
                with col3:
                    if depth_smoothness > 0.7:
                        st.success(f"âœ… **YumuÅŸak YÃ¼zey**: {depth_smoothness:.3f}")
                    elif depth_smoothness > 0.4:
                        st.warning(f"âš ï¸ **Orta YÃ¼zey**: {depth_smoothness:.3f}")
                    else:
                        st.error(f"âŒ **KarmaÅŸÄ±k YÃ¼zey**: {depth_smoothness:.3f}")
                
            except Exception as e:
                st.error(f"âŒ Derinlik analizi hatasÄ±: {e}")
        else:
            st.info("ðŸ“¸ Derinlik analizi iÃ§in Ã¶nce bir gÃ¶rÃ¼ntÃ¼ yÃ¼kleyin.")
    
    with tab3:
        st.header("ðŸ“Š Sistem Durumu")
        
        # Model bilgileri
        st.subheader("ðŸ¤– Hibrit Model Bilgileri")
        
        if 'autoencoder' in models:
            total_params = sum(p.numel() for p in models['autoencoder'].parameters())
            model_size_mb = total_params * 4 / (1024 * 1024)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Autoencoder Parametreleri", f"{total_params:,}")
            
            with col2:
                st.metric("Autoencoder Boyutu", f"{model_size_mb:.2f} MB")
            
            with col3:
                st.metric("Latent Boyutu", "1024")
        
        if 'classifier' in models:
            classifier_params = sum(p.numel() for p in models['classifier'].parameters())
            classifier_size_mb = classifier_params * 4 / (1024 * 1024)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("SÄ±nÄ±flandÄ±rÄ±cÄ± Parametreleri", f"{classifier_params:,}")
            
            with col2:
                st.metric("SÄ±nÄ±flandÄ±rÄ±cÄ± Boyutu", f"{classifier_size_mb:.2f} MB")
            
            with col3:
                st.metric("SÄ±nÄ±f SayÄ±sÄ±", "5")
        
        # EÄŸitim verisi analizi
        st.subheader("ðŸ“ˆ EÄŸitim Verisi")
        
        data_dir = Path("mars_images")
        categories = {}
        total_images = 0
        
        if data_dir.exists():
            for split in ['train', 'valid']:
                split_dir = data_dir / split
                if split_dir.exists():
                    for category_dir in split_dir.iterdir():
                        if category_dir.is_dir():
                            category = category_dir.name
                            image_count = len(list(category_dir.glob("*.jpg"))) + len(list(category_dir.glob("*.png")))
                            categories[category] = categories.get(category, 0) + image_count
                            total_images += image_count
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("Toplam GÃ¶rÃ¼ntÃ¼", total_images)
            st.metric("Kategori SayÄ±sÄ±", len(categories))
        
        with col2:
            # Kategori daÄŸÄ±lÄ±mÄ± grafiÄŸi
            if categories:
                fig = px.pie(
                    values=list(categories.values()),
                    names=list(categories.keys()),
                    title="Kategori DaÄŸÄ±lÄ±mÄ±"
                )
                st.plotly_chart(fig, use_container_width=True)
    
    with tab4:
        st.header("ðŸŽ¯ Demo Veriler")
        
        # Demo gÃ¶rÃ¼ntÃ¼leri
        st.subheader("ðŸ“¸ Test GÃ¶rÃ¼ntÃ¼leri")
        
        # Curiosity verilerinden Ã¶rnekler
        data_dir = Path("mars_images/valid")
        demo_images = []
        
        if data_dir.exists():
            for category_dir in data_dir.iterdir():
                if category_dir.is_dir():
                    image_files = list(category_dir.glob("*.jpg")) + list(category_dir.glob("*.png"))
                    if image_files:
                        demo_images.append((category_dir.name, str(image_files[0])))
                        if len(demo_images) >= 6:
                            break
        
        if demo_images:
            # Demo gÃ¶rÃ¼ntÃ¼lerini gÃ¶ster
            cols = st.columns(3)
            
            for i, (category, img_path) in enumerate(demo_images):
                with cols[i % 3]:
                    image = Image.open(img_path)
                    st.image(image, caption=f"{category}", use_container_width=True)
                    
                    # HÄ±zlÄ± analiz butonu
                    if st.button(f"ðŸ” {category} Hibrit Analiz", key=f"demo_{i}"):
                        with st.spinner(f"{category} hibrit analiz ediliyor..."):
                            results = analyze_mars_image(models, image)
                            if results['anomaly_score'] is not None:
                                st.success(f"Anomali: {results['anomaly_score']:.6f}")
                                st.success(f"Bilinen DeÄŸer: {results['known_value_score']:.3f}")
                                
                                # Ä°lginÃ§lik puanÄ±
                                curiosity_score = alpha * results['known_value_score'] + beta * results['anomaly_score']
                                st.metric("Ä°lginÃ§lik PuanÄ±", f"{curiosity_score:.6f}")
    
    with tab5:
        st.header("â„¹ï¸ ARTPS Hibrit Sistem HakkÄ±nda")
        
        st.markdown("""
        ## ðŸš€ ARTPS - Otonom Bilimsel KeÅŸif Sistemi (Hibrit)
        
        **ARTPS (Autonomous Rover Target Prioritization System)**, Mars rover'larÄ±nÄ±n 
        DÃ¼nya'dan komut beklemeden bilimsel olarak ilginÃ§ hedefleri tespit etmesini 
        saÄŸlayan **hibrit yapay zeka sistemidir**.
        
        **ðŸ›°ï¸ YapÄ±m:** [Poyraz BAYDEMÄ°R](https://github.com/Poyqraz) Â· [ResearchGate DOI](http://dx.doi.org/10.13140/RG.2.2.12215.18088)  
        **ðŸ“„ Lisans:** [MIT License](https://github.com/Poyqraz/ARTPS/blob/main/LICENSE)
        
        ### ðŸŽ¯ Sistem AmacÄ±
        - Mars yÃ¼zeyinde bilimsel olarak deÄŸerli hedefleri otonom olarak tespit etmek
        - **Derinlik algÄ±sÄ±** ile 3D analiz yapmak
        - **Dinamik "Bilinen DeÄŸer"** puanÄ± hesaplamak
        - Hedefleri Ã¶ncelik sÄ±rasÄ±na gÃ¶re sÄ±ralamak
        - Rover'Ä±n verimliliÄŸini artÄ±rmak
        
        ### ðŸ”¬ Hibrit Teknik Ã–zellikler (GÃ¼ncel)
        - **Convolutional Autoencoder**: Anomali tespiti (optimize 17M param.)
        - **Derinlik GeliÅŸtirilmiÅŸ SÄ±nÄ±flandÄ±rÄ±cÄ±**: Dinamik deÄŸer (RGB latent + 14 derinlik Ã¶z.)
        - **DPT_Large Derinlik Tahmini**: YÃ¼ksek doÄŸruluk (CUDA hÄ±zlandÄ±rmalÄ±)
        - **PaDiM (Patch Distribution Modeling)**: GÃ¶rÃ¼ntÃ¼ tabanlÄ± anomaliyi AE+Derinlik ile fÃ¼zyon
        - **Ã‡ok Ã–lÃ§ekli Ä°nce Detay**: Laplacian(3,5) + DoG ile kÃ¼Ã§Ã¼k taÅŸ/kum Ã§izgisi vurgusu
        - **Uzak Alan Hassasiyeti**: YakÄ±nlÄ±k karÄ±ÅŸÄ±mÄ± ve derinliÄŸe koÅŸullu alan eÅŸiÄŸi
        - **Curiosity Verileri**: ~2,575 gÃ¶rÃ¼ntÃ¼ (train/valid)
        - **OdaÄŸa YumuÅŸak Maske**: SeÃ§ili hedef Ã§evresinde Gauss geÃ§iÅŸli vurgulama
        
        ### ðŸ“Š GeliÅŸmiÅŸ Ä°lginÃ§lik PuanÄ±
        ```
        Ä°lginÃ§lik PuanÄ± = Î± Ã— Dinamik Bilinen DeÄŸer + Î² Ã— Anomali Skoru
        ```
        
        - **Î± (Alfa)**: Dinamik bilinen deÄŸer aÄŸÄ±rlÄ±ÄŸÄ± (0-1)
        - **Î² (Beta)**: Anomali/keÅŸif aÄŸÄ±rlÄ±ÄŸÄ± (0-1)
        - **Dinamik Bilinen DeÄŸer**: Kategori bazlÄ± otomatik etiketleme (0-1)
        
        ### ðŸŒŠ Derinlik Analizi (GÃ¼ncel)
        - **DPT_Large**: YÃ¼ksek doÄŸruluklu monocular depth, rehberli iyileÅŸtirme ve filtreleme
        - **14 Derinlik Ã–zelliÄŸi**: Ortalama, std, min, max, yÃ¼zey karmaÅŸÄ±klÄ±ÄŸÄ±, gradient vb.
        - **Uzak/ YakÄ±n Denge**: Uzak alanlarda kÃ¼Ã§Ã¼k detaylarÄ± korumak iÃ§in eÅŸik uyarlama
        - **3D/2D GÃ¶rselleÅŸtirme**: Turbo colormap, 3D yÃ¼zey, histogram ve istatistikler
        
        ### ðŸŽ® Hibrit KullanÄ±m
        1. Mars gÃ¶rÃ¼ntÃ¼sÃ¼ yÃ¼kleyin
        2. Parametreleri ayarlayÄ±n (Î±, Î²)
        3. "Hibrit Analiz Et" butonuna basÄ±n
        4. Anomali + Derinlik + Dinamik DeÄŸer sonuÃ§larÄ±nÄ± inceleyin
        
        ### ðŸ” GeliÅŸmiÅŸ Anomali Tespiti
        - **DÃ¼ÅŸÃ¼k MSE**: Normal Mars yÃ¼zeyi
        - **YÃ¼ksek MSE**: Anormal/ilginÃ§ hedef
        - **Derinlik Entegrasyonu**: 3D anomali tespiti
        - **Dinamik SÄ±nÄ±flandÄ±rma**: Otomatik kategori belirleme
        
        ### ðŸ“ˆ Hibrit Model PerformansÄ±
        - **Anomali Tespiti**: %95+ doÄŸruluk
        - **SÄ±nÄ±flandÄ±rma**: %74 doÄŸruluk
        - **Derinlik Tahmini**: DPT_Large (YÃ¼ksek DoÄŸruluk) + Fallback
        - **GerÃ§ek ZamanlÄ±**: <1 saniye analiz sÃ¼resi
        
        ### ðŸš€ Gelecek GeliÅŸtirmeler
        - Perseverance verileri entegrasyonu
        - GeliÅŸmiÅŸ segmentasyon algoritmalarÄ±
        - Stereo vision entegrasyonu
        - GerÃ§ek zamanlÄ± rover entegrasyonu
        - Ã‡oklu rover desteÄŸi
        - Uzay istasyonu entegrasyonu
        """)

if __name__ == "__main__":
    main() 