"""
Basit Model Analizi
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
from pathlib import Path
from src.models.optimized_autoencoder import OptimizedAutoencoder

def analyze_training_data():
    """EÄŸitim verilerini analiz et"""
    
    print("ğŸ” EÄŸitim Verilerini Analiz Ediliyor...")
    
    data_dir = Path("mars_images")
    
    # Kategori daÄŸÄ±lÄ±mÄ±nÄ± analiz et
    categories = {}
    total_images = 0
    
    for split in ['train', 'valid']:
        split_dir = data_dir / split
        if split_dir.exists():
            for category_dir in split_dir.iterdir():
                if category_dir.is_dir():
                    category = category_dir.name
                    image_count = len(list(category_dir.glob("*.jpg"))) + len(list(category_dir.glob("*.png")))
                    categories[category] = categories.get(category, 0) + image_count
                    total_images += image_count
    
    print(f"\nğŸ“Š EÄŸitim Veri Analizi:")
    print(f"Toplam gÃ¶rÃ¼ntÃ¼: {total_images}")
    print(f"Kategori sayÄ±sÄ±: {len(categories)}")
    
    print("\nKategori daÄŸÄ±lÄ±mÄ±:")
    for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / total_images) * 100
        print(f"  {category}: {count} gÃ¶rÃ¼ntÃ¼ ({percentage:.1f}%)")
    
    return categories, total_images

def load_trained_model():
    """EÄŸitilen modeli yÃ¼kle"""
    
    print("\nğŸ¤– EÄŸitilen Model YÃ¼kleniyor...")
    
    model_path = "results/optimized_autoencoder_curiosity_data.pth"
    
    if not os.path.exists(model_path):
        print(f"âŒ Model dosyasÄ± bulunamadÄ±: {model_path}")
        return None
    
    # Model oluÅŸtur
    model = OptimizedAutoencoder(input_channels=3, latent_dim=1024)
    
    # EÄŸitilen aÄŸÄ±rlÄ±klarÄ± yÃ¼kle
    checkpoint = torch.load(model_path, map_location='cpu')
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    print(f"âœ… Model yÃ¼klendi: {model_path}")
    print(f"Model parametre sayÄ±sÄ±: {sum(p.numel() for p in model.parameters()):,}")
    
    return model

def test_simple_reconstruction():
    """Basit yeniden oluÅŸturma testi"""
    
    print("\nğŸ”„ Basit Yeniden OluÅŸturma Testi...")
    
    model = load_trained_model()
    if model is None:
        return
    
    # Test gÃ¶rÃ¼ntÃ¼sÃ¼ seÃ§
    data_dir = Path("mars_images/valid")
    test_image_path = None
    
    if data_dir.exists():
        for category_dir in data_dir.iterdir():
            if category_dir.is_dir():
                image_files = list(category_dir.glob("*.jpg")) + list(category_dir.glob("*.png"))
                if image_files:
                    test_image_path = str(image_files[0])
                    break
    
    if not test_image_path:
        print("âŒ Test gÃ¶rÃ¼ntÃ¼sÃ¼ bulunamadÄ±")
        return
    
    try:
        # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
        image = Image.open(test_image_path).convert('RGB')
        image = image.resize((128, 128), Image.LANCZOS)
        image_array = np.array(image, dtype=np.float32) / 255.0
        
        # Tensor'a Ã§evir
        input_tensor = torch.from_numpy(image_array).float()
        input_tensor = input_tensor.permute(2, 0, 1).unsqueeze(0)
        
        # Model tahmini
        with torch.no_grad():
            reconstructed, latent = model(input_tensor)
        
        # SonuÃ§larÄ± gÃ¶rselleÅŸtir
        reconstructed = reconstructed.squeeze(0).permute(1, 2, 0).numpy()
        reconstructed = np.clip(reconstructed, 0, 1)
        
        # MSE hesapla
        mse = np.mean((image_array - reconstructed) ** 2)
        
        print(f"Test gÃ¶rÃ¼ntÃ¼sÃ¼: {Path(test_image_path).parent.name}")
        print(f"MSE: {mse:.6f}")
        
        # GÃ¶rselleÅŸtir
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        axes[0].imshow(image_array)
        axes[0].set_title("Orijinal GÃ¶rÃ¼ntÃ¼")
        axes[0].axis('off')
        
        axes[1].imshow(reconstructed)
        axes[1].set_title(f"Yeniden OluÅŸturulan\nMSE: {mse:.6f}")
        axes[1].axis('off')
        
        # Fark gÃ¶rÃ¼ntÃ¼sÃ¼
        diff = np.abs(image_array - reconstructed)
        axes[2].imshow(diff, cmap='hot')
        axes[2].set_title("Fark GÃ¶rÃ¼ntÃ¼sÃ¼")
        axes[2].axis('off')
        
        plt.tight_layout()
        plt.savefig('results/simple_reconstruction_test.png', dpi=150, bbox_inches='tight')
        plt.show()
        
        print("âœ… Yeniden oluÅŸturma testi tamamlandÄ±!")
        
    except Exception as e:
        print(f"âŒ Hata: {e}")

def test_anomaly_detection():
    """Basit anomali tespiti testi"""
    
    print("\nğŸš¨ Basit Anomali Tespiti Testi...")
    
    model = load_trained_model()
    if model is None:
        return
    
    # Test durumlarÄ±
    test_cases = []
    
    # Normal Mars gÃ¶rÃ¼ntÃ¼sÃ¼
    data_dir = Path("mars_images/valid")
    if data_dir.exists():
        for category_dir in data_dir.iterdir():
            if category_dir.is_dir():
                image_files = list(category_dir.glob("*.jpg")) + list(category_dir.glob("*.png"))
                if image_files:
                    test_cases.append(("Normal Mars", str(image_files[0])))
                    break
    
    # Anormal gÃ¶rÃ¼ntÃ¼ler
    test_cases.append(("Rastgele Noise", np.random.rand(128, 128, 3).astype(np.float32)))
    test_cases.append(("Siyah GÃ¶rÃ¼ntÃ¼", np.zeros((128, 128, 3), dtype=np.float32)))
    test_cases.append(("Beyaz GÃ¶rÃ¼ntÃ¼", np.ones((128, 128, 3), dtype=np.float32)))
    
    results = []
    
    for case_name, img_data in test_cases:
        try:
            if isinstance(img_data, str):
                # Dosyadan yÃ¼kle
                image = Image.open(img_data).convert('RGB')
                image = image.resize((128, 128), Image.LANCZOS)
                image_array = np.array(image, dtype=np.float32) / 255.0
            else:
                # NumPy array
                image_array = img_data
            
            # Tensor'a Ã§evir
            input_tensor = torch.from_numpy(image_array).float()
            input_tensor = input_tensor.permute(2, 0, 1).unsqueeze(0)
            
            # Model tahmini
            with torch.no_grad():
                reconstructed, _ = model(input_tensor)
            
            # MSE hesapla
            reconstructed = reconstructed.squeeze(0).permute(1, 2, 0).numpy()
            mse = np.mean((image_array - reconstructed) ** 2)
            
            results.append((case_name, mse, image_array, reconstructed))
            print(f"  {case_name}: Anomali Skoru = {mse:.6f}")
            
        except Exception as e:
            print(f"  Hata ({case_name}): {e}")
    
    # SonuÃ§larÄ± gÃ¶rselleÅŸtir
    if results:
        fig, axes = plt.subplots(2, len(results), figsize=(4*len(results), 8))
        
        for i, (case_name, mse, original, reconstructed) in enumerate(results):
            # Orijinal
            axes[0, i].imshow(original)
            axes[0, i].set_title(f"{case_name}\nOrijinal")
            axes[0, i].axis('off')
            
            # Yeniden oluÅŸturulan
            axes[1, i].imshow(reconstructed)
            axes[1, i].set_title(f"Yeniden OluÅŸturulan\nMSE: {mse:.6f}")
            axes[1, i].axis('off')
        
        plt.tight_layout()
        plt.savefig('results/simple_anomaly_test.png', dpi=150, bbox_inches='tight')
        plt.show()
    
    print("âœ… Anomali tespiti testi tamamlandÄ±!")

def generate_model_summary():
    """Model Ã¶zeti oluÅŸtur"""
    
    print("\nğŸ“‹ MODEL Ã–ZETÄ°")
    print("=" * 50)
    
    # EÄŸitim verisi analizi
    categories, total_images = analyze_training_data()
    
    # Model bilgileri
    model = load_trained_model()
    if model:
        total_params = sum(p.numel() for p in model.parameters())
        model_size_mb = total_params * 4 / (1024 * 1024)
        
        print(f"\nğŸ¤– Model Bilgileri:")
        print(f"  Parametre sayÄ±sÄ±: {total_params:,}")
        print(f"  Model boyutu: {model_size_mb:.2f} MB")
        print(f"  Latent boyutu: 1024")
        print(f"  GiriÅŸ boyutu: 128x128x3")
        
        print(f"\nğŸ“Š EÄŸitim Verisi:")
        print(f"  Toplam gÃ¶rÃ¼ntÃ¼: {total_images}")
        print(f"  Kategori sayÄ±sÄ±: {len(categories)}")
        
        print(f"\nğŸ¯ Model Ne Ã–ÄŸrendi:")
        print(f"  - Mars yÃ¼zey gÃ¶rÃ¼ntÃ¼lerinin normal gÃ¶rÃ¼nÃ¼mÃ¼")
        print(f"  - FarklÄ± Mars yÃ¼zey kategorileri:")
        for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"    * {category}: {count} gÃ¶rÃ¼ntÃ¼")
        
        print(f"\nğŸ” Model Ne Yapabilir:")
        print(f"  âœ… Normal Mars gÃ¶rÃ¼ntÃ¼lerini yeniden oluÅŸturabilir")
        print(f"  âœ… Anormal gÃ¶rÃ¼ntÃ¼leri tespit edebilir (yÃ¼ksek MSE)")
        print(f"  âœ… GÃ¶rÃ¼ntÃ¼leri 1024 boyutlu latent space'e sÄ±kÄ±ÅŸtÄ±rabilir")
        
        print(f"\nâŒ Model Ne Yapamaz:")
        print(f"  - Perseverance verilerini tanÄ±maz (sadece Curiosity)")
        print(f"  - Yeni Mars bÃ¶lgelerini tanÄ±maz")
        print(f"  - DÃ¼nya gÃ¶rÃ¼ntÃ¼lerini anlamaz")

if __name__ == "__main__":
    print("ğŸš€ Basit Model Analizi BaÅŸlÄ±yor...")
    
    # 1. EÄŸitim verisi analizi
    analyze_training_data()
    
    # 2. Basit yeniden oluÅŸturma testi
    test_simple_reconstruction()
    
    # 3. Basit anomali tespiti testi
    test_anomaly_detection()
    
    # 4. Model Ã¶zeti
    generate_model_summary()
    
    print("\nâœ… Basit model analizi tamamlandÄ±!") 