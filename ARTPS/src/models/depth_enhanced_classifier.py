"""
ARTPS - Derinlik GeliÅŸtirilmiÅŸ Kategori BazlÄ± SÄ±nÄ±flandÄ±rÄ±cÄ±
Derinlik algÄ±sÄ± + kategori bazlÄ± otomatik etiketleme
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np
from PIL import Image
import os
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import cv2

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from src.models.depth_estimation import MiDaSDepthEstimator
from src.models.optimized_autoencoder import OptimizedAutoencoder

class DepthEnhancedClassifier(nn.Module):
    """
    Derinlik geliÅŸtirilmiÅŸ bilimsel deÄŸer sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±
    """
    
    def __init__(self, num_classes=5, rgb_features=1024, depth_features=14):
        super(DepthEnhancedClassifier, self).__init__()
        
        # RGB Ã¶zellikleri iÃ§in (autoencoder latent features)
        self.rgb_feature_extractor = nn.Sequential(
            nn.Linear(rgb_features, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
        
        # Derinlik Ã¶zellikleri iÃ§in
        self.depth_feature_extractor = nn.Sequential(
            nn.Linear(depth_features, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU()
        )
        
        # BirleÅŸtirilmiÅŸ Ã¶zellikler iÃ§in sÄ±nÄ±flandÄ±rÄ±cÄ±
        combined_features = 256 + 32  # RGB + Depth features
        self.classifier = nn.Sequential(
            nn.Linear(combined_features, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, num_classes),
            nn.Softmax(dim=1)
        )
    
    def forward(self, rgb_features, depth_features):
        """
        Forward pass
        
        Args:
            rgb_features: Autoencoder latent features
            depth_features: Derinlik Ã¶zellikleri
            
        Returns:
            Predictions: SÄ±nÄ±flandÄ±rma tahminleri
        """
        # RGB Ã¶zelliklerini iÅŸle
        rgb_processed = self.rgb_feature_extractor(rgb_features)
        
        # Derinlik Ã¶zelliklerini iÅŸle
        depth_processed = self.depth_feature_extractor(depth_features)
        
        # Ã–zellikleri birleÅŸtir
        combined = torch.cat([rgb_processed, depth_processed], dim=1)
        
        # SÄ±nÄ±flandÄ±r
        predictions = self.classifier(combined)
        
        return predictions

class DepthEnhancedDataset(Dataset):
    """
    Derinlik geliÅŸtirilmiÅŸ veri seti
    """
    
    def __init__(self, data_dir, autoencoder_model, depth_estimator, transform=None):
        self.data_dir = Path(data_dir)
        self.autoencoder = autoencoder_model
        self.depth_estimator = depth_estimator
        self.transform = transform
        self.samples = []
        
        # Kategori bazlÄ± bilimsel deÄŸer etiketleri
        self.value_labels = {
            'rocky': 4,        # YÃ¼ksek deÄŸer - KarmaÅŸÄ±k jeoloji
            'boulder': 3,      # Orta-yÃ¼ksek deÄŸer - BÃ¼yÃ¼k kayalar
            'hills_or_ridge': 3, # Orta-yÃ¼ksek deÄŸer - YapÄ±sal Ã¶zellikler
            'flat_terrain': 1, # DÃ¼ÅŸÃ¼k deÄŸer - SÄ±radan yÃ¼zey
            'dusty': 1,        # DÃ¼ÅŸÃ¼k deÄŸer - Tozlu yÃ¼zey
            'rover': 0,        # DeÄŸersiz - Rover parÃ§alarÄ±
        }
        
        self._load_samples()
    
    def _load_samples(self):
        """Veri setini yÃ¼kle"""
        print("ğŸ“Š Veri seti yÃ¼kleniyor...")
        
        for split in ['train', 'valid']:
            split_dir = self.data_dir / split
            if split_dir.exists():
                for category_dir in split_dir.iterdir():
                    if category_dir.is_dir():
                        category = category_dir.name
                        if category in self.value_labels:
                            label = self.value_labels[category]
                            image_files = list(category_dir.glob("*.jpg")) + list(category_dir.glob("*.png"))
                            
                            for img_file in image_files:
                                self.samples.append({
                                    'image_path': str(img_file),
                                    'category': category,
                                    'value_label': label
                                })
        
        print(f"âœ… {len(self.samples)} Ã¶rnek yÃ¼klendi")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        try:
            # GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kle
            image = Image.open(sample['image_path']).convert('RGB')
            image = image.resize((128, 128), Image.LANCZOS)
            image_array = np.array(image, dtype=np.float32) / 255.0
            
            # Autoencoder ile RGB latent features Ã§Ä±kar
            with torch.no_grad():
                input_tensor = torch.from_numpy(image_array).float()
                input_tensor = input_tensor.permute(2, 0, 1).unsqueeze(0)
                _, latent_features = self.autoencoder(input_tensor)
                latent_features = latent_features.squeeze()
            
            # Derinlik tahmini yap
            depth_map, _ = self.depth_estimator.estimate_depth(image_array)
            
            # Derinlik Ã¶zelliklerini Ã§Ä±kar
            depth_features = self.depth_estimator.extract_depth_features(depth_map)
            depth_features_tensor = torch.tensor(list(depth_features.values()), dtype=torch.float32)
            
            return {
                'rgb_features': latent_features,
                'depth_features': depth_features_tensor,
                'value_label': torch.tensor(sample['value_label'], dtype=torch.long),
                'category': sample['category'],
                'image_path': sample['image_path'],
                'depth_map': depth_map
            }
            
        except Exception as e:
            print(f"âŒ Hata ({sample['image_path']}): {e}")
            # Fallback: SÄ±fÄ±r Ã¶zellikler
            return {
                'rgb_features': torch.zeros(1024),
                'depth_features': torch.zeros(14),
                'value_label': torch.tensor(sample['value_label'], dtype=torch.long),
                'category': sample['category'],
                'image_path': sample['image_path'],
                'depth_map': np.zeros((128, 128))
            }

def create_depth_enhanced_classifier():
    """
    Derinlik geliÅŸtirilmiÅŸ sÄ±nÄ±flandÄ±rÄ±cÄ± oluÅŸtur ve eÄŸit
    """
    
    print("ğŸš€ Derinlik GeliÅŸtirilmiÅŸ SÄ±nÄ±flandÄ±rÄ±cÄ± OluÅŸturuluyor...")
    
    # 1. Modelleri yÃ¼kle
    print("ğŸ“¥ Modeller yÃ¼kleniyor...")
    
    # Autoencoder
    autoencoder_path = "results/optimized_autoencoder_curiosity_extended.pth"
    if not os.path.exists(autoencoder_path):
        print(f"âŒ Autoencoder model bulunamadÄ±: {autoencoder_path}")
        return None
    
    autoencoder = OptimizedAutoencoder(input_channels=3, latent_dim=1024)
    checkpoint = torch.load(autoencoder_path, map_location='cpu')
    autoencoder.load_state_dict(checkpoint['model_state_dict'])
    autoencoder.eval()
    
    # Derinlik tahmin modÃ¼lÃ¼
    depth_estimator = MiDaSDepthEstimator(model_type="DPT_Large")
    
    # 2. Veri setini oluÅŸtur
    print("ğŸ“Š Veri seti oluÅŸturuluyor...")
    dataset = DepthEnhancedDataset("mars_images", autoencoder, depth_estimator)
    
    if len(dataset) == 0:
        print("âŒ Veri seti boÅŸ!")
        return None
    
    # Kategori daÄŸÄ±lÄ±mÄ±nÄ± analiz et
    category_counts = {}
    value_distribution = {}
    
    for sample in dataset.samples:
        category = sample['category']
        value = sample['value_label']
        
        category_counts[category] = category_counts.get(category, 0) + 1
        value_distribution[value] = value_distribution.get(value, 0) + 1
    
    print("\nğŸ“ˆ Kategori DaÄŸÄ±lÄ±mÄ±:")
    for category, count in sorted(category_counts.items()):
        print(f"  {category}: {count} Ã¶rnek")
    
    print("\nğŸ¯ Bilimsel DeÄŸer DaÄŸÄ±lÄ±mÄ±:")
    value_names = {0: "DeÄŸersiz", 1: "DÃ¼ÅŸÃ¼k", 2: "Orta", 3: "Orta-YÃ¼ksek", 4: "YÃ¼ksek"}
    for value, count in sorted(value_distribution.items()):
        print(f"  {value_names[value]} ({value}): {count} Ã¶rnek")
    
    # 3. Veri setini bÃ¶l
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    
    # 4. DataLoader'larÄ± oluÅŸtur
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
    
    # 5. Model oluÅŸtur
    num_classes = 5  # 0-4 arasÄ± deÄŸer kategorileri
    classifier = DepthEnhancedClassifier(num_classes=num_classes, rgb_features=1024, depth_features=14)
    
    # 6. EÄŸitim parametreleri
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    classifier = classifier.to(device)
    
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
    
    # 7. EÄŸitim dÃ¶ngÃ¼sÃ¼
    num_epochs = 30
    train_losses = []
    val_losses = []
    best_val_loss = float('inf')
    
    print(f"\nğŸ“ EÄŸitim baÅŸlÄ±yor ({num_epochs} epoch)...")
    
    for epoch in range(num_epochs):
        # EÄŸitim
        classifier.train()
        train_loss = 0.0
        for batch in train_loader:
            rgb_features = batch['rgb_features'].to(device)
            depth_features = batch['depth_features'].to(device)
            labels = batch['value_label'].to(device)
            
            optimizer.zero_grad()
            outputs = classifier(rgb_features, depth_features)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
        
        # Validasyon
        classifier.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch in val_loader:
                rgb_features = batch['rgb_features'].to(device)
                depth_features = batch['depth_features'].to(device)
                labels = batch['value_label'].to(device)
                
                outputs = classifier(rgb_features, depth_features)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        train_loss /= len(train_loader)
        val_loss /= len(val_loader)
        accuracy = 100 * correct / total
        
        train_losses.append(train_loss)
        val_losses.append(val_loss)
        
        print(f"Epoch [{epoch+1:2d}/{num_epochs}] - "
              f"Train Loss: {train_loss:.4f}, "
              f"Val Loss: {val_loss:.4f}, "
              f"Accuracy: {accuracy:.2f}%")
        
        # En iyi modeli kaydet
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save({
                'model_state_dict': classifier.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'epoch': epoch,
                'val_loss': val_loss,
                'accuracy': accuracy
            }, "results/depth_enhanced_classifier.pth")
            print(f"  âœ… Yeni en iyi model kaydedildi")
    
    # 8. EÄŸitim eÄŸrilerini Ã§iz
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Train Loss', color='blue')
    plt.plot(val_losses, label='Validation Loss', color='red')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Derinlik GeliÅŸtirilmiÅŸ SÄ±nÄ±flandÄ±rÄ±cÄ± EÄŸitimi')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 2, 2)
    plt.plot(val_losses, label='Validation Loss', color='red', linewidth=2)
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Validasyon Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('results/depth_enhanced_classifier_training.png', dpi=150, bbox_inches='tight')
    plt.show()
    
    print(f"\nâœ… Derinlik geliÅŸtirilmiÅŸ sÄ±nÄ±flandÄ±rÄ±cÄ± eÄŸitimi tamamlandÄ±!")
    print(f"ğŸ“ Model kaydedildi: results/depth_enhanced_classifier.pth")
    print(f"ğŸ¯ En iyi validasyon loss: {best_val_loss:.4f}")
    print(f"ğŸ“Š Final doÄŸruluk: {accuracy:.2f}%")
    
    return classifier

def test_depth_enhanced_classifier():
    """
    Derinlik geliÅŸtirilmiÅŸ sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± test et
    """
    
    print("ğŸ§ª Derinlik GeliÅŸtirilmiÅŸ SÄ±nÄ±flandÄ±rÄ±cÄ± Test Ediliyor...")
    
    # Model yÃ¼kle
    classifier_path = "results/depth_enhanced_classifier.pth"
    if not os.path.exists(classifier_path):
        print(f"âŒ SÄ±nÄ±flandÄ±rÄ±cÄ± model bulunamadÄ±: {classifier_path}")
        return
    
    # Autoencoder yÃ¼kle
    autoencoder_path = "results/optimized_autoencoder_curiosity_extended.pth"
    autoencoder = OptimizedAutoencoder(input_channels=3, latent_dim=1024)
    checkpoint = torch.load(autoencoder_path, map_location='cpu')
    autoencoder.load_state_dict(checkpoint['model_state_dict'])
    autoencoder.eval()
    
    # Derinlik tahmin modÃ¼lÃ¼
    depth_estimator = MiDaSDepthEstimator(model_type="DPT_Large")
    
    # SÄ±nÄ±flandÄ±rÄ±cÄ± yÃ¼kle
    classifier = DepthEnhancedClassifier(num_classes=5, rgb_features=1024, depth_features=14)
    checkpoint = torch.load(classifier_path, map_location='cpu')
    classifier.load_state_dict(checkpoint['model_state_dict'])
    classifier.eval()
    
    # Test veri seti oluÅŸtur
    test_dataset = DepthEnhancedDataset("mars_images", autoencoder, depth_estimator)
    
    # Test et
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    classifier = classifier.to(device)
    
    all_predictions = []
    all_labels = []
    all_categories = []
    
    with torch.no_grad():
        for i in range(min(50, len(test_dataset))):  # Ä°lk 50 Ã¶rnek
            sample = test_dataset[i]
            rgb_features = sample['rgb_features'].unsqueeze(0).to(device)
            depth_features = sample['depth_features'].unsqueeze(0).to(device)
            label = sample['value_label']
            category = sample['category']
            
            output = classifier(rgb_features, depth_features)
            _, predicted = torch.max(output, 1)
            
            all_predictions.append(predicted.item())
            all_labels.append(label.item())
            all_categories.append(category)
    
    # SonuÃ§larÄ± analiz et
    print("\nğŸ“Š SÄ±nÄ±flandÄ±rma Raporu:")
    value_names = {0: "DeÄŸersiz", 1: "DÃ¼ÅŸÃ¼k", 2: "Orta", 3: "Orta-YÃ¼ksek", 4: "YÃ¼ksek"}
    
    # GerÃ§ek sÄ±nÄ±f sayÄ±sÄ±nÄ± kontrol et
    unique_labels = sorted(set(all_labels))
    unique_predictions = sorted(set(all_predictions))
    
    print(f"GerÃ§ek sÄ±nÄ±flar: {unique_labels}")
    print(f"Tahmin edilen sÄ±nÄ±flar: {unique_predictions}")
    
    # Sadece mevcut sÄ±nÄ±flar iÃ§in rapor oluÅŸtur
    available_classes = sorted(set(all_labels + all_predictions))
    target_names = [value_names.get(i, f"SÄ±nÄ±f_{i}") for i in available_classes]
    
    print(classification_report(all_labels, all_predictions, 
                               labels=available_classes,
                               target_names=target_names))
    
    # Kategori bazlÄ± analiz
    print("\nğŸ¯ Kategori BazlÄ± Bilimsel DeÄŸer Tahminleri:")
    category_predictions = {}
    for i, category in enumerate(all_categories):
        if category not in category_predictions:
            category_predictions[category] = []
        category_predictions[category].append(all_predictions[i])
    
    for category, predictions in category_predictions.items():
        avg_value = np.mean(predictions)
        print(f"  {category}: Ortalama DeÄŸer = {avg_value:.2f} ({value_names[int(avg_value)]})")
    
    return classifier

if __name__ == "__main__":
    print("ğŸš€ Derinlik GeliÅŸtirilmiÅŸ Kategori BazlÄ± SÄ±nÄ±flandÄ±rÄ±cÄ± Projesi")
    print("=" * 60)
    
    # 1. SÄ±nÄ±flandÄ±rÄ±cÄ± oluÅŸtur ve eÄŸit
    classifier = create_depth_enhanced_classifier()
    
    if classifier:
        # 2. Test et
        test_depth_enhanced_classifier()
    
    print("\nâœ… Proje tamamlandÄ±!") 